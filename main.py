import asyncio
import json
import os
import re
import shlex
import shutil
from typing import Optional
from urllib.parse import urljoin

import aiohttp

from astrbot.api import star
from astrbot.api.event import AstrMessageEvent, filter
from astrbot.core import logger
from astrbot.core.config import AstrBotConfig
from astrbot.core.utils.session_waiter import SessionController, session_waiter


class BiliDownloader(star.Star):
    """Bç«™è§†é¢‘ä¸‹è½½æ’ä»¶"""
    
    # ä¸­æ–‡å‚æ•°ååˆ°è‹±æ–‡å‚æ•°åçš„æ˜ å°„
    PARAM_MAPPING = {
        # å•ä¸ªè§†é¢‘å‚æ•°ï¼ˆå¤§å†™ï¼‰
        "<è§†é¢‘æ ‡é¢˜>": "<videoTitle>",
        "<BVå·>": "<bvid>",
        "<AID>": "<aid>",
        "<CID>": "<cid>",
        "<æ¸…æ™°åº¦>": "<dfn>",
        "<åˆ†è¾¨ç‡>": "<res>",
        "<å¸§ç‡>": "<fps>",
        "<è§†é¢‘ç¼–ç >": "<videoCodecs>",
        "<è§†é¢‘ç ç‡>": "<videoBandwidth>",
        "<éŸ³é¢‘ç¼–ç >": "<audioCodecs>",
        "<éŸ³é¢‘ç ç‡>": "<audioBandwidth>",
        "<UPä¸»åç§°>": "<ownerName>",
        "<UPä¸»MID>": "<ownerMid>",
        "<å‘å¸ƒæ—¶é—´>": "<publishDate>",
        "<APIç±»å‹>": "<apiType>",
        # åˆ†Pè§†é¢‘é¢å¤–å‚æ•°ï¼ˆå¤§å†™ï¼‰
        "<åˆ†Påºå·>": "<pageNumber>",
        "<åˆ†Påºå·è¡¥é›¶>": "<pageNumberWithZero>",
        "<åˆ†Pæ ‡é¢˜>": "<pageTitle>",
        # å…¼å®¹å°å†™
        "<bvå·>": "<bvid>",
        "<aid>": "<aid>",
        "<cid>": "<cid>",
        "<upä¸»åç§°>": "<ownerName>",
        "<upä¸»mid>": "<ownerMid>",
        "<apiç±»å‹>": "<apiType>",
        "<åˆ†påºå·>": "<pageNumber>",
        "<åˆ†påºå·è¡¥é›¶>": "<pageNumberWithZero>",
        "<åˆ†pæ ‡é¢˜>": "<pageTitle>",
    }

    def __init__(self, context: star.Context, config: AstrBotConfig | dict | None = None):
        super().__init__(context, config)
        
        # è·å–é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„configï¼Œå¦åˆ™ä»metadataè·å–
        if config:
            if isinstance(config, AstrBotConfig):
                self.config = dict(config)
            else:
                self.config = config
        else:
            # ä»metadataè·å–é…ç½®
            plugin_metadata = self.context.get_registered_star("bilidownloader")
            if plugin_metadata and plugin_metadata.config:
                self.config = dict(plugin_metadata.config)
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                self.config = {
                    "bbdown_path": "BBDown",
                    "download_path": "./downloads",
                    "cookie": "",
                    "classify_by_owner": True,
                    "default_options": {
                        "quality": "",
                        "download_danmaku": False,
                        "download_subtitle": True,
                    },
                    "naming": {
                        "single_video_pattern": "<è§†é¢‘æ ‡é¢˜>[<æ¸…æ™°åº¦>]",
                        "multi_video_pattern": "<è§†é¢‘æ ‡é¢˜>/[P<åˆ†Påºå·è¡¥é›¶>]<åˆ†Pæ ‡é¢˜>[<æ¸…æ™°åº¦>]",
                    }
                }
        
        # åˆå§‹åŒ–é…ç½®å€¼
        self._update_config_values()
        
        # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
        os.makedirs(self.download_path, exist_ok=True)
        
        # åˆå§‹åŒ–æƒé™é…ç½®ï¼ˆpermissionsåœ¨alistå¯¹è±¡ä¸‹ï¼‰
        alist_config = self.config.get("alist", {})
        self.permissions = alist_config.get("permissions", {})
        self.open_groups = self.permissions.get("open_groups", [])
        # restricted_groups å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆJSONæ ¼å¼ï¼‰æˆ–å­—å…¸
        restricted_groups_raw = self.permissions.get("restricted_groups", "{}")
        if isinstance(restricted_groups_raw, str):
            try:
                self.restricted_groups = json.loads(restricted_groups_raw) if restricted_groups_raw.strip() else {}
            except json.JSONDecodeError:
                logger.warning(f"restricted_groups JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºå¯¹è±¡: {restricted_groups_raw}")
                self.restricted_groups = {}
        else:
            self.restricted_groups = restricted_groups_raw or {}

    async def initialize(self):
        """æ’ä»¶åˆå§‹åŒ–æ—¶è°ƒç”¨ï¼Œé‡æ–°åŠ è½½é…ç½®"""
        # é‡æ–°ä»metadataè·å–é…ç½®ï¼ˆå¯èƒ½åœ¨WebUIä¸­æ›´æ–°äº†ï¼‰
        plugin_metadata = self.context.get_registered_star("bilidownloader")
        if plugin_metadata and plugin_metadata.config:
            self.config = dict(plugin_metadata.config)
            self._update_config_values()
            # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
            os.makedirs(self.download_path, exist_ok=True)
            # é‡æ–°åŠ è½½æƒé™é…ç½®ï¼ˆpermissionsåœ¨alistå¯¹è±¡ä¸‹ï¼‰
            alist_config = self.config.get("alist", {})
            self.permissions = alist_config.get("permissions", {})
            self.open_groups = self.permissions.get("open_groups", [])
            # restricted_groups å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆJSONæ ¼å¼ï¼‰æˆ–å­—å…¸
            restricted_groups_raw = self.permissions.get("restricted_groups", "{}")
            if isinstance(restricted_groups_raw, str):
                try:
                    self.restricted_groups = json.loads(restricted_groups_raw) if restricted_groups_raw.strip() else {}
                except json.JSONDecodeError:
                    logger.warning(f"restricted_groups JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºå¯¹è±¡: {restricted_groups_raw}")
                    self.restricted_groups = {}
            else:
                self.restricted_groups = restricted_groups_raw or {}

    def _update_config_values(self):
        """æ›´æ–°é…ç½®å€¼åˆ°å®ä¾‹å˜é‡"""
        self.bbdown_path = self.config.get("bbdown_path", "BBDown")
        self.download_path = self.config.get("download_path", "./downloads")

    def _parse_cookie(self, cookie_input: str) -> str:
        """è§£æä¸åŒæ ¼å¼çš„ cookie
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        1. æµè§ˆå™¨æ ¼å¼: "name1=value1; name2=value2; name3=value3"
        2. Netscape æ ¼å¼: "# Netscape HTTP Cookie File\n...\n.domain.com\tTRUE\t/\tFALSE\t1234567890\tname\tvalue"
        3. JSON æ ¼å¼: '{"name1": "value1", "name2": "value2"}'
        4. çº¯æ–‡æœ¬é”®å€¼å¯¹: "name1=value1\nname2=value2"
        5. å·²ç»æ˜¯ BBDown æ ¼å¼: "SESSDATA=xxx; DedeUserID=xxx"
        """
        cookie_input = cookie_input.strip()
        if not cookie_input:
            return ""
        
        # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼ˆåŒ…å« SESSDATA ç­‰ï¼‰ï¼Œç›´æ¥è¿”å›
        if "SESSDATA=" in cookie_input or "DedeUserID=" in cookie_input:
            # æ¸…ç†å¯èƒ½çš„æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼
            cookie_str = re.sub(r'\s+', ' ', cookie_input)
            cookie_str = cookie_str.replace('\n', ' ').replace('\r', ' ')
            return cookie_str.strip()
        
        # å°è¯•è§£æ Netscape æ ¼å¼
        if cookie_input.startswith("#") or "\t" in cookie_input:
            cookies = {}
            for line in cookie_input.split("\n"):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                parts = line.split("\t")
                if len(parts) >= 7:
                    name = parts[5]
                    value = parts[6]
                    cookies[name] = value
            return "; ".join([f"{k}={v}" for k, v in cookies.items()])
        
        # å°è¯•è§£æ JSON æ ¼å¼
        if cookie_input.startswith("{") or cookie_input.startswith("["):
            try:
                cookie_obj = json.loads(cookie_input)
                if isinstance(cookie_obj, dict):
                    return "; ".join([f"{k}={v}" for k, v in cookie_obj.items()])
                elif isinstance(cookie_obj, list):
                    return "; ".join([f"{item.get('name', '')}={item.get('value', '')}" 
                                     for item in cookie_obj if isinstance(item, dict)])
            except json.JSONDecodeError:
                pass
        
        # å°è¯•è§£æçº¯æ–‡æœ¬é”®å€¼å¯¹ï¼ˆå¤šè¡Œï¼‰
        if "\n" in cookie_input:
            cookies = {}
            for line in cookie_input.split("\n"):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                if "=" in line:
                    parts = line.split("=", 1)
                    if len(parts) == 2:
                        cookies[parts[0].strip()] = parts[1].strip()
            if cookies:
                return "; ".join([f"{k}={v}" for k, v in cookies.items()])
        
        # é»˜è®¤æŒ‰æµè§ˆå™¨æ ¼å¼å¤„ç†ï¼ˆåˆ†å·åˆ†éš”ï¼‰
        return cookie_input

    def _get_current_config(self) -> dict:
        """è·å–å½“å‰æœ€æ–°é…ç½®"""
        plugin_metadata = self.context.get_registered_star("bilidownloader")
        if plugin_metadata and plugin_metadata.config:
            return dict(plugin_metadata.config)
        return self.config

    def _convert_chinese_params(self, pattern: str) -> str:
        """å°†ä¸­æ–‡å‚æ•°åè½¬æ¢ä¸ºè‹±æ–‡å‚æ•°å
        
        Args:
            pattern: åŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡å‚æ•°åçš„å‘½åæ ¼å¼å­—ç¬¦ä¸²
            
        Returns:
            è½¬æ¢åçš„å‘½åæ ¼å¼å­—ç¬¦ä¸²ï¼ˆè‹±æ–‡å‚æ•°åï¼‰
        """
        if not pattern:
            return pattern
        
        result = pattern
        # æŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œé¿å…çŸ­å‚æ•°åè¢«é•¿å‚æ•°åçš„ä¸€éƒ¨åˆ†æ›¿æ¢
        sorted_mapping = sorted(self.PARAM_MAPPING.items(), key=lambda x: len(x[0]), reverse=True)
        
        for chinese_param, english_param in sorted_mapping:
            result = result.replace(chinese_param, english_param)
        
        return result

    def _build_bbdown_command(self, url: str, cookie: Optional[str] = None, 
                              quality: Optional[str] = None, 
                              download_danmaku: bool = False,
                              download_subtitle: bool = True,
                              pages: Optional[str] = None) -> list:
        """æ„å»º BBDown å‘½ä»¤"""
        # è·å–æœ€æ–°é…ç½®
        current_config = self._get_current_config()
        current_bbdown_path = current_config.get("bbdown_path", "BBDown")
        current_download_path = current_config.get("download_path", "./downloads")
        
        cmd = [current_bbdown_path]
        
        # æ·»åŠ  URL
        cmd.append(url)
        
        # æ·»åŠ  Cookie
        cookie_to_use = cookie or current_config.get("cookie", "")
        if cookie_to_use:
            parsed_cookie = self._parse_cookie(cookie_to_use)
            if parsed_cookie:
                cmd.extend(["-c", parsed_cookie])
        
        # æ·»åŠ æ¸…æ™°åº¦
        quality_to_use = quality or current_config.get("default_options", {}).get("quality", "")
        if quality_to_use:
            cmd.extend(["-q", quality_to_use])
        
        # æ·»åŠ å¼¹å¹•ä¸‹è½½
        if download_danmaku or current_config.get("default_options", {}).get("download_danmaku", False):
            cmd.append("--download-danmaku")
        
        # æ·»åŠ å­—å¹•ä¸‹è½½
        if download_subtitle and current_config.get("default_options", {}).get("download_subtitle", True):
            cmd.append("--download-subtitle")
        
        # æ·»åŠ åˆ†Pé€‰æ‹©
        if pages:
            # pageså¯ä»¥æ˜¯ "ALL", "1", "1-3", "1,2,3" ç­‰æ ¼å¼
            if pages.upper() == "ALL":
                # BBDowné»˜è®¤ä¸‹è½½å…¨éƒ¨ï¼Œä¸éœ€è¦æ·»åŠ å‚æ•°
                pass
            else:
                cmd.extend(["-p", pages])
        
        # æ·»åŠ æ–‡ä»¶å‘½åæ ¼å¼ï¼ˆè½¬æ¢ä¸­æ–‡å‚æ•°ä¸ºè‹±æ–‡ï¼‰
        naming_config = current_config.get("naming", {})
        single_pattern = naming_config.get("single_video_pattern", "")
        multi_pattern = naming_config.get("multi_video_pattern", "")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨å‘½åæ ¼å¼ä¸­æ·»åŠ UPä¸»æ–‡ä»¶å¤¹åˆ†ç±»
        classify_by_owner = current_config.get("classify_by_owner", True)
        
        if single_pattern:
            # è½¬æ¢ä¸­æ–‡å‚æ•°ä¸ºè‹±æ–‡å‚æ•°
            single_pattern_en = self._convert_chinese_params(single_pattern)
            # å¦‚æœå¯ç”¨æŒ‰UPä¸»åˆ†ç±»ä¸”æ ¼å¼ä¸­æ²¡æœ‰åŒ…å«ownerNameæ–‡ä»¶å¤¹ï¼Œåˆ™æ·»åŠ 
            if classify_by_owner:
                # æ£€æŸ¥æ ¼å¼ä¸­æ˜¯å¦å·²ç»åŒ…å«ownerNameæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä»¥<ownerName>/å¼€å¤´æˆ–åŒ…å«/<ownerName>/ï¼‰
                # æ³¨æ„ï¼šåªæ£€æŸ¥æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¸æ£€æŸ¥æ–‡ä»¶åä¸­çš„<ownerName>
                pattern_lower = single_pattern_en.lower()
                if not pattern_lower.startswith("<ownername>/") and "/<ownername>/" not in pattern_lower:
                    single_pattern_en = "<ownerName>/" + single_pattern_en
            cmd.extend(["--file-pattern", single_pattern_en])
        elif classify_by_owner:
            # å¦‚æœæ²¡æœ‰è®¾ç½®å‘½åæ ¼å¼ä½†å¯ç”¨äº†åˆ†ç±»ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
            cmd.extend(["--file-pattern", "<ownerName>/<videoTitle>[<dfn>]"])
        else:
            # å¦‚æœæ²¡æœ‰è®¾ç½®å‘½åæ ¼å¼ä¸”ä¸åˆ†ç±»ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
            cmd.extend(["--file-pattern", "<videoTitle>[<dfn>]"])
            
        if multi_pattern:
            # è½¬æ¢ä¸­æ–‡å‚æ•°ä¸ºè‹±æ–‡å‚æ•°
            multi_pattern_en = self._convert_chinese_params(multi_pattern)
            # å¦‚æœå¯ç”¨æŒ‰UPä¸»åˆ†ç±»ä¸”æ ¼å¼ä¸­æ²¡æœ‰åŒ…å«ownerNameæ–‡ä»¶å¤¹ï¼Œåˆ™æ·»åŠ 
            if classify_by_owner:
                # æ£€æŸ¥æ ¼å¼ä¸­æ˜¯å¦å·²ç»åŒ…å«ownerNameæ–‡ä»¶å¤¹è·¯å¾„
                pattern_lower = multi_pattern_en.lower()
                if not pattern_lower.startswith("<ownername>/") and "/<ownername>/" not in pattern_lower:
                    multi_pattern_en = "<ownerName>/" + multi_pattern_en
            cmd.extend(["--multi-file-pattern", multi_pattern_en])
        elif classify_by_owner:
            # å¦‚æœæ²¡æœ‰è®¾ç½®å‘½åæ ¼å¼ä½†å¯ç”¨äº†åˆ†ç±»ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
            cmd.extend(["--multi-file-pattern", "<ownerName>/<videoTitle>/[P<pageNumberWithZero>]<pageTitle>[<dfn>]"])
        else:
            # å¦‚æœæ²¡æœ‰è®¾ç½®å‘½åæ ¼å¼ä¸”ä¸åˆ†ç±»ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
            cmd.extend(["--multi-file-pattern", "<videoTitle>/[P<pageNumberWithZero>]<pageTitle>[<dfn>]"])
        
        # æ·»åŠ ä¸‹è½½è·¯å¾„ï¼ˆBBDownä½¿ç”¨--work-dirå‚æ•°ï¼‰
        # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…åœ¨ä¸åŒå¹³å°ä¸‹çš„è·¯å¾„è§£æé—®é¢˜
        abs_download_path = os.path.abspath(current_download_path)
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(abs_download_path, exist_ok=True)
        cmd.extend(["--work-dir", abs_download_path])
        
        logger.debug(f"BBDownä¸‹è½½è·¯å¾„: {abs_download_path}")
        
        return cmd

    def _extract_short_url(self, result: dict) -> Optional[str]:
        """ä»APIå“åº”ä¸­æå–çŸ­é“¾ï¼ˆæ”¯æŒå¤šç§å“åº”æ ¼å¼ï¼‰
        
        Args:
            result: APIå“åº”çš„JSONå¯¹è±¡
        
        Returns:
            str: çŸ­é“¾ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        return (
            result.get("shorturl") or  # YOURLSæ ¼å¼
            result.get("short_url") or  # ShortLinks (FastAPI)æ ¼å¼
            result.get("url") or
            result.get("link") or
            result.get("data", {}).get("shorturl") or
            result.get("data", {}).get("short_url") or
            result.get("data", {}).get("url") or
            result.get("data", {}).get("shortUrl") or
            result.get("data", {}).get("link")
        )
    
    async def _shorten_url(self, url: str, shortener_config: Optional[dict] = None) -> Optional[str]:
        """å°†é•¿é“¾æ¥è½¬æ¢ä¸ºçŸ­é“¾
        
        æ”¯æŒå¤šç§çŸ­é“¾æœåŠ¡ï¼š
        - ShortLinks (FastAPI): æ”¯æŒHeaderæˆ–Queryå‚æ•°è®¤è¯
        - YOURLS: éœ€è¦APIå¯†é’¥ï¼Œé€šè¿‡URLå‚æ•°ä¼ é€’
        - Polr: æ”¯æŒAPIå¯†é’¥è®¤è¯
        - Kutt: æ”¯æŒAPIå¯†é’¥è®¤è¯
        - Shlink: æ”¯æŒAPIå¯†é’¥è®¤è¯
        - è‡ªå®šä¹‰æœåŠ¡: æ ¹æ®é…ç½®çµæ´»é€‚é…
        
        Args:
            url: åŸå§‹é“¾æ¥
            shortener_config: çŸ­é“¾æœåŠ¡é…ç½®
        
        Returns:
            str: çŸ­é“¾ï¼Œå¦‚æœè½¬æ¢å¤±è´¥åˆ™è¿”å›Noneï¼ˆè°ƒç”¨æ–¹ä¼šä½¿ç”¨åŸé“¾æ¥ï¼‰
        """
        if not shortener_config or not shortener_config.get("enabled", False):
            return None
        
        api_url = shortener_config.get("api_url", "")
        if not api_url:
            return None
        
        # ç®€å•çš„URLæ ¼å¼éªŒè¯
        if not url or not (url.startswith("http://") or url.startswith("https://")):
            logger.warning(f"æ— æ•ˆçš„URLæ ¼å¼ï¼Œè·³è¿‡çŸ­é“¾è½¬æ¢: {url[:50]}")
            return None
        
        try:
            import aiohttp
            
            logger.debug(f"å¼€å§‹çŸ­é“¾è½¬æ¢: API={api_url}, URLé•¿åº¦={len(url)}")
            
            # æ„å»ºè¯·æ±‚å¤´
            headers = {"Content-Type": "application/json"}
            
            # è·å–APIå¯†é’¥å’Œè®¤è¯æ–¹å¼
            api_key = shortener_config.get("api_key", "")
            auth_method = shortener_config.get("auth_method", "header")  # header æˆ– query
            auth_header = shortener_config.get("auth_header", "X-API-Key")
            
            # æ ¹æ®è®¤è¯æ–¹å¼è®¾ç½®è®¤è¯ä¿¡æ¯
            params = {}
            if api_key:
                if auth_method.lower() == "query":
                    # Queryå‚æ•°æ–¹å¼ï¼šæ·»åŠ åˆ°URLå‚æ•°ä¸­
                    params["api_key"] = api_key
                    logger.debug(f"ä½¿ç”¨Queryå‚æ•°è®¤è¯: api_key={api_key[:10]}...")
                else:
                    # Headeræ–¹å¼ï¼ˆé»˜è®¤ï¼‰ï¼šæ·»åŠ åˆ°è¯·æ±‚å¤´
                    headers[auth_header] = api_key
                    logger.debug(f"ä½¿ç”¨Headerè®¤è¯: {auth_header}={api_key[:10]}...")
            
            method = shortener_config.get("method", "POST").upper()
            logger.debug(f"è¯·æ±‚æ–¹æ³•: {method}")
            
            # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œé¿å…Linuxä¸Šç½‘ç»œå»¶è¿Ÿå¯¼è‡´å¤±è´¥
            # total: æ€»è¶…æ—¶æ—¶é—´ï¼ˆåŒ…æ‹¬è¿æ¥ã€å‘é€ã€æ¥æ”¶ï¼‰
            # connect: è¿æ¥è¶…æ—¶æ—¶é—´
            # å¦‚æœç½‘ç»œè¾ƒæ…¢ï¼Œå¯ä»¥é€‚å½“å¢åŠ è¿™äº›å€¼
            timeout = aiohttp.ClientTimeout(total=15, connect=10)
            
            if method == "POST":
                # POSTæ–¹å¼ï¼šè¯·æ±‚ä½“åŒ…å«åŸå§‹URL
                data_key = shortener_config.get("data_key", "url")
                data = {data_key: url}
                logger.debug(f"POSTè¯·æ±‚ä½“: {data_key}={url[:100]}...")
                
                async with aiohttp.ClientSession() as session:
                    try:
                        async with session.post(api_url, json=data, headers=headers, params=params, timeout=timeout) as resp:
                            response_text = await resp.text()
                            logger.debug(f"çŸ­é“¾APIå“åº”çŠ¶æ€: {resp.status}, å“åº”é•¿åº¦: {len(response_text)}")
                            
                            if resp.status == 200:
                                try:
                                    result = await resp.json()
                                    logger.debug(f"çŸ­é“¾APIå“åº”: {result}")
                                    short_url = self._extract_short_url(result)
                                    if short_url:
                                        logger.info(f"çŸ­é“¾è½¬æ¢æˆåŠŸ: {url[:50]}... -> {short_url}")
                                        return short_url
                                    else:
                                        logger.warning(f"çŸ­é“¾APIå“åº”ä¸­æœªæ‰¾åˆ°çŸ­é“¾å­—æ®µï¼Œå“åº”å†…å®¹: {result}")
                                except Exception as e:
                                    logger.warning(f"è§£æçŸ­é“¾APIå“åº”å¤±è´¥: {e}, å“åº”æ–‡æœ¬: {response_text[:500]}")
                                    import traceback
                                    logger.debug(traceback.format_exc())
                            else:
                                logger.warning(f"çŸ­é“¾APIè¿”å›é”™è¯¯: HTTP {resp.status}, å“åº”: {response_text[:500]}")
                    except asyncio.TimeoutError:
                        logger.warning(f"çŸ­é“¾APIè¯·æ±‚è¶…æ—¶: {api_url}")
                    except aiohttp.ClientError as e:
                        logger.warning(f"çŸ­é“¾APIè¯·æ±‚å¤±è´¥: {type(e).__name__}: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())
            else:
                # GETæ–¹å¼ï¼šURLä½œä¸ºå‚æ•°
                params_key = shortener_config.get("params_key", "url")
                params[params_key] = url
                logger.debug(f"GETè¯·æ±‚å‚æ•°: {params_key}={url[:100]}...")
                
                async with aiohttp.ClientSession() as session:
                    try:
                        async with session.get(api_url, params=params, headers=headers, timeout=timeout) as resp:
                            response_text = await resp.text()
                            logger.debug(f"çŸ­é“¾APIå“åº”çŠ¶æ€: {resp.status}, å“åº”é•¿åº¦: {len(response_text)}")
                            
                            if resp.status == 200:
                                try:
                                    result = await resp.json()
                                    logger.debug(f"çŸ­é“¾APIå“åº”: {result}")
                                    short_url = self._extract_short_url(result)
                                    if short_url:
                                        logger.info(f"çŸ­é“¾è½¬æ¢æˆåŠŸ: {url[:50]}... -> {short_url}")
                                        return short_url
                                    else:
                                        logger.warning(f"çŸ­é“¾APIå“åº”ä¸­æœªæ‰¾åˆ°çŸ­é“¾å­—æ®µï¼Œå“åº”å†…å®¹: {result}")
                                except Exception as e:
                                    logger.warning(f"è§£æçŸ­é“¾APIå“åº”å¤±è´¥: {e}, å“åº”æ–‡æœ¬: {response_text[:500]}")
                                    import traceback
                                    logger.debug(traceback.format_exc())
                            else:
                                logger.warning(f"çŸ­é“¾APIè¿”å›é”™è¯¯: HTTP {resp.status}, å“åº”: {response_text[:500]}")
                    except aiohttp.ServerTimeoutError as e:
                        logger.warning(f"çŸ­é“¾APIæœåŠ¡å™¨è¶…æ—¶ï¼ˆæ€»è¶…æ—¶15ç§’ï¼‰: {api_url}, é”™è¯¯: {e}")
                        logger.warning(f"å¯èƒ½åŸå› ï¼šç½‘ç»œå»¶è¿Ÿã€æœåŠ¡å™¨å“åº”æ…¢æˆ–ç½‘ç»œè¿æ¥é—®é¢˜")
                    except asyncio.TimeoutError:
                        logger.warning(f"çŸ­é“¾APIè¯·æ±‚è¶…æ—¶ï¼ˆæ€»è¶…æ—¶15ç§’ï¼‰: {api_url}")
                        logger.warning(f"å¯èƒ½åŸå› ï¼šç½‘ç»œå»¶è¿Ÿã€æœåŠ¡å™¨å“åº”æ…¢æˆ–ç½‘ç»œè¿æ¥é—®é¢˜")
                    except aiohttp.ClientConnectorError as e:
                        logger.warning(f"çŸ­é“¾APIè¿æ¥å¤±è´¥: {api_url}, é”™è¯¯: {e}")
                        logger.warning(f"å¯èƒ½åŸå› ï¼šç½‘ç»œä¸é€šã€DNSè§£æå¤±è´¥æˆ–æœåŠ¡å™¨ä¸å¯è¾¾")
                    except aiohttp.ClientError as e:
                        logger.warning(f"çŸ­é“¾APIè¯·æ±‚å¤±è´¥: {type(e).__name__}: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())
        except Exception as e:
            logger.warning(f"çŸ­é“¾è½¬æ¢å¤±è´¥: {type(e).__name__}: {e}")
            import traceback
            logger.debug(traceback.format_exc())
        
        return None
    
    async def _get_alist_download_link(self, base_url: str, file_path: str, password: str, local_file_path: Optional[str] = None) -> Optional[str]:
        """é€šè¿‡OpenList APIè·å–æ–‡ä»¶çš„çœŸå®ä¸‹è½½é“¾æ¥ï¼ˆä½¿ç”¨å¯†ç æ–¹å¼ï¼‰
        
        Args:
            base_url: OpenListè®¿é—®åœ°å€
            file_path: æ–‡ä»¶åœ¨OpenListä¸­çš„è·¯å¾„ï¼ˆå¦‚ /bilibili/UPä¸»åç§°/è§†é¢‘.mp4ï¼‰
            password: æ–‡ä»¶å¤¹å¯†ç ï¼ˆå¿…éœ€ï¼‰
            local_file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼‰
        
        Returns:
            str: æ–‡ä»¶çš„çœŸå®ä¸‹è½½é“¾æ¥ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # å¦‚æœæä¾›äº†æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if local_file_path:
                if not os.path.exists(local_file_path):
                    logger.warning(f"[OpenList API] æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯·æ±‚: {local_file_path}")
                    return None
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœæ–‡ä»¶å¤§å°ä¸º0ï¼Œå¯èƒ½è¿˜åœ¨ä¸‹è½½ä¸­ï¼‰
                file_size = os.path.getsize(local_file_path)
                if file_size == 0:
                    logger.warning(f"[OpenList API] æ–‡ä»¶å¤§å°ä¸º0ï¼Œå¯èƒ½è¿˜åœ¨ä¸‹è½½ä¸­ï¼Œè·³è¿‡è¯·æ±‚: {local_file_path}")
                    return None
            
            api_url = f"{base_url}/api/fs/get"
            
            # æ„å»ºè¯·æ±‚ä½“ï¼ˆä½¿ç”¨å¯†ç æ–¹å¼ï¼‰
            data = {
                "path": file_path,
                "password": password
            }
            
            # æ„å»ºè¯·æ±‚å¤´ï¼ˆä¸ä½¿ç”¨tokenï¼‰
            headers = {"Content-Type": "application/json"}
            
            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, json=data, headers=headers, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    response_text = await resp.text()
                    
                    if resp.status != 200:
                        logger.error(f"OpenList APIè¯·æ±‚å¤±è´¥: HTTP {resp.status}")
                        logger.error(f"å“åº”å†…å®¹: {response_text}")
                        return None
                    
                    try:
                        result = await resp.json()
                    except Exception as e:
                        logger.error(f"è§£æAPIå“åº”JSONå¤±è´¥: {e}")
                        logger.error(f"åŸå§‹å“åº”: {response_text}")
                        return None
                    
                    if result.get("code") != 200:
                        error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        error_code = result.get('code', 'æœªçŸ¥')
                        logger.error(f"OpenList APIè¿”å›é”™è¯¯: code={error_code}, message={error_msg}")
                        return None
                    
                    # è·å–æ–‡ä»¶çš„çœŸå®ä¸‹è½½é“¾æ¥
                    # æ ¹æ®OpenList APIæ–‡æ¡£ï¼Œè¿”å›æ ¼å¼ä¸º: {"code": 200, "data": {"url": "ç›´é“¾"}}
                    file_data = result.get("data", {})
                    
                    if not file_data:
                        logger.error("APIå“åº”ä¸­æ²¡æœ‰dataå­—æ®µ")
                        return None
                    
                    # æ£€æŸ¥è¿”å›çš„æ˜¯ç›®å½•è¿˜æ˜¯æ–‡ä»¶
                    if file_data.get("is_dir", False):
                        logger.error(f"è¿”å›çš„æ˜¯ç›®å½•è€Œéæ–‡ä»¶: {file_path}")
                        return None
                    
                    # æ ¹æ®APIæ–‡æ¡£ï¼Œè·å–data.urlï¼ˆè¿™æ˜¯APIè¿”å›çš„ç›´é“¾ï¼‰
                    direct_url = file_data.get("url") or file_data.get("raw_url")
                    if direct_url:
                        return direct_url
                    
                    logger.error("APIå“åº”ä¸­æ²¡æœ‰urlå­—æ®µ")
                    return None
                        
        except Exception as e:
            logger.error(f"è·å–OpenListä¸‹è½½é“¾æ¥å¤±è´¥: {e}")
            return None
    
    async def _generate_alist_links_async(self, config: dict, video_title: str, page_info: list, selected_pages: Optional[str] = None) -> list:
        """ç”ŸæˆOpenListä¸‹è½½é“¾æ¥ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œä½¿ç”¨OpenList APIè·å–çœŸå®é“¾æ¥ï¼‰
        
        å·¥ä½œåŸç†ï¼š
        1. æ‰«æä¸‹è½½ç›®å½•ï¼Œé€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
        2. æ ¹æ®é…ç½®çš„OpenListå­˜å‚¨è·¯å¾„ï¼Œæ„å»ºæ–‡ä»¶åœ¨OpenListä¸­çš„è·¯å¾„
        3. å¦‚æœæœ‰API Tokenï¼Œè°ƒç”¨OpenList APIè·å–çœŸå®çš„ä¸‹è½½é“¾æ¥
        4. å¦‚æœæ²¡æœ‰API Tokenï¼Œä½¿ç”¨è·¯å¾„æ‹¼æ¥æ–¹å¼
        
        Args:
            config: å½“å‰é…ç½®
            video_title: è§†é¢‘æ ‡é¢˜ï¼ˆç”¨äºåŒ¹é…æ–‡ä»¶ï¼‰
            page_info: åˆ†Pä¿¡æ¯åˆ—è¡¨ï¼ˆç”¨äºåŒ¹é…æ–‡ä»¶ï¼‰
            selected_pages: ç”¨æˆ·é€‰æ‹©çš„åˆ†Pï¼ˆç”¨äºåŒ¹é…æ–‡ä»¶ï¼‰
        
        Returns:
            list: åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« name å’Œ url
        """
        alist_config = config.get("alist", {})
        if not alist_config.get("enabled", False):
            logger.debug("OpenListæœªå¯ç”¨")
            return []
        
        base_url = alist_config.get("base_url", "").rstrip("/")
        if not base_url:
            logger.warning("OpenListå·²å¯ç”¨ä½†æœªé…ç½®base_url")
            return []
        
        # è·å–æ–‡ä»¶å¤¹å¯†ç ï¼ˆå¦‚æœç›®å½•æ²¡æœ‰å¯†ç ï¼Œå¯ä»¥ç•™ç©ºï¼‰
        password = alist_config.get("password", "").strip()
        
        # è·å–OpenListå­˜å‚¨è·¯å¾„ï¼ˆä¾‹å¦‚ï¼š/bilibiliï¼‰
        alist_storage_path = alist_config.get("alist_storage_path", "/bilibili").rstrip("/")
        if not alist_storage_path.startswith("/"):
            alist_storage_path = "/" + alist_storage_path
        
        download_path = config.get("download_path", "./downloads")
        
        try:
            import time
            # è·å–ä¸‹è½½ç›®å½•çš„ç»å¯¹è·¯å¾„
            abs_download_path = os.path.abspath(download_path)
            
            if not os.path.exists(abs_download_path):
                logger.warning(f"ä¸‹è½½ç›®å½•ä¸å­˜åœ¨: {abs_download_path}")
                return []
            
            # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶ï¼ˆ.mp4, .flvç­‰ï¼‰
            video_extensions = ['.mp4', '.flv', '.m4s', '.mkv']
            
            # å‡†å¤‡æ–‡ä»¶ååŒ¹é…å…³é”®è¯
            match_keywords = []
            if video_title:
                # æå–è§†é¢‘æ ‡é¢˜çš„å…³é”®éƒ¨åˆ†ï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºåŒ¹é…ï¼‰
                title_clean = video_title.replace(" ", "").replace("-", "").replace("_", "")
                if len(title_clean) > 10:
                    match_keywords.append(title_clean[:20])  # å–å‰20ä¸ªå­—ç¬¦
                else:
                    match_keywords.append(title_clean)
            
            # å¦‚æœæœ‰åˆ†Pä¿¡æ¯ï¼Œä¹ŸåŠ å…¥åŒ¹é…å…³é”®è¯
            if page_info:
                for page in page_info:
                    # æå–åˆ†Pæ ‡é¢˜
                    if ":" in page:
                        page_title = page.split(":", 1)[1].strip()
                        if page_title:
                            page_title_clean = page_title.replace(" ", "").replace("-", "").replace("_", "")
                            if page_title_clean:
                                match_keywords.append(page_title_clean[:15])
            
            logger.info(f"æ–‡ä»¶ååŒ¹é…å…³é”®è¯: {match_keywords}")
            
            # é€’å½’æŸ¥æ‰¾æ‰€æœ‰è§†é¢‘æ–‡ä»¶
            def scan_directory(dir_path: str, base_dir: str) -> list:
                """é€’å½’æ‰«æç›®å½•ï¼Œé€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°å¯¹åº”çš„è§†é¢‘æ–‡ä»¶"""
                found_files = []
                try:
                    items = os.listdir(dir_path)
                    logger.debug(f"æ‰«æç›®å½• {dir_path}ï¼Œæ‰¾åˆ° {len(items)} ä¸ªé¡¹ç›®")
                    
                    for item in items:
                        item_path = os.path.join(dir_path, item)
                        
                        if os.path.isfile(item_path):
                            # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶
                            file_ext = os.path.splitext(item)[1].lower()
                            if file_ext in video_extensions:
                                # é€šè¿‡æ–‡ä»¶ååŒ¹é…
                                item_clean = item.replace(" ", "").replace("-", "").replace("_", "")
                                
                                # å¦‚æœæœ‰å…³é”®è¯ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«å…³é”®è¯
                                # å¦‚æœæ²¡æœ‰å…³é”®è¯ï¼ˆå¯èƒ½æ˜¯BBDownè¾“å‡ºè§£æå¤±è´¥ï¼‰ï¼Œåˆ™æ¥å—æ‰€æœ‰è§†é¢‘æ–‡ä»¶
                                if match_keywords:
                                    matched = any(keyword.lower() in item_clean.lower() for keyword in match_keywords if keyword)
                                    if not matched:
                                        logger.debug(f"æ–‡ä»¶åä¸åŒ¹é…ï¼Œè·³è¿‡: {item}")
                                        continue
                                else:
                                    # æ²¡æœ‰åŒ¹é…å…³é”®è¯æ—¶ï¼Œè®°å½•ä¿¡æ¯ï¼ˆå¯èƒ½æ˜¯è¾“å‡ºè§£æå¤±è´¥ï¼Œä½†æ–‡ä»¶å·²ä¸‹è½½ï¼‰
                                    logger.info(f"æ²¡æœ‰åŒ¹é…å…³é”®è¯ï¼Œæ¥å—æ‰€æœ‰è§†é¢‘æ–‡ä»¶: {item}")
                                
                                logger.info(f"æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶: {item}")
                                
                                # è®¡ç®—ç›¸å¯¹äºä¸‹è½½ç›®å½•çš„è·¯å¾„
                                relative_path = os.path.relpath(item_path, base_dir)
                                # è½¬æ¢ä¸ºAlistè·¯å¾„æ ¼å¼ï¼ˆä½¿ç”¨æ­£æ–œæ ï¼‰
                                alist_file_path = relative_path.replace("\\", "/")
                                # ç»„åˆå®Œæ•´çš„Alistè·¯å¾„
                                full_alist_path = f"{alist_storage_path}/{alist_file_path}"
                                
                                found_files.append({
                                    "name": item,
                                    "alist_path": full_alist_path,
                                    "path": item_path
                                })
                                logger.debug(f"  æ·»åŠ åˆ°åˆ—è¡¨: {item} -> {full_alist_path}")
                        elif os.path.isdir(item_path):
                            # é€’å½’æ‰«æå­ç›®å½•
                            logger.debug(f"è¿›å…¥å­ç›®å½•: {item_path}")
                            found_files.extend(scan_directory(item_path, base_dir))
                except Exception as e:
                    logger.error(f"æ‰«æç›®å½•å¤±è´¥ {dir_path}: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
                
                return found_files
            
            # æ‰«æä¸‹è½½ç›®å½•
            logger.info(f"æ‰«æä¸‹è½½ç›®å½•: {abs_download_path}")
            
            files = scan_directory(abs_download_path, abs_download_path)
            
            if not files:
                logger.warning("æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶")
                return []
            
            # æœ€å¤šå¤„ç†10ä¸ªæ–‡ä»¶
            files = files[:10]
            
            # ä½¿ç”¨å¯†ç æ–¹å¼è·å–çœŸå®é“¾æ¥
            try:
                tasks = [self._get_alist_download_link(base_url, f["alist_path"], password, f["path"]) for f in files]
                links = await asyncio.gather(*tasks, return_exceptions=False)
            except Exception as e:
                logger.error(f"è·å–OpenListé“¾æ¥å¤±è´¥: {e}")
                import traceback
                logger.error(traceback.format_exc())
                links = [None] * len(files)
            
            # ç»„åˆç»“æœï¼ˆåªåŒ…å«æˆåŠŸè·å–é“¾æ¥çš„æ–‡ä»¶ï¼‰
            result = []
            # è·å–çŸ­é“¾é…ç½®
            shortener_config = alist_config.get("shortener", {})
            
            # å‡†å¤‡éœ€è¦è½¬æ¢çš„é“¾æ¥åˆ—è¡¨
            valid_links = []
            file_indices = []
            for i, file_info in enumerate(files):
                if i < len(links) and links[i] is not None:
                    valid_links.append(links[i])
                    file_indices.append(i)
            
            # å¦‚æœå¯ç”¨äº†çŸ­é“¾æœåŠ¡ï¼Œå¹¶è¡Œè½¬æ¢æ‰€æœ‰é“¾æ¥
            if shortener_config.get("enabled", False) and valid_links:
                logger.info(f"å¼€å§‹è½¬æ¢ {len(valid_links)} ä¸ªé“¾æ¥ä¸ºçŸ­é“¾...")
                try:
                    short_tasks = [self._shorten_url(url, shortener_config) for url in valid_links]
                    short_urls = await asyncio.gather(*short_tasks, return_exceptions=True)
                    # è®°å½•è½¬æ¢ç»“æœ
                    success_count = sum(1 for url in short_urls if url and not isinstance(url, Exception))
                    logger.info(f"çŸ­é“¾è½¬æ¢å®Œæˆ: {success_count}/{len(valid_links)} æˆåŠŸ")
                    for i, (original, short) in enumerate(zip(valid_links, short_urls)):
                        if isinstance(short, Exception):
                            logger.warning(f"é“¾æ¥ {i+1} è½¬æ¢å¤±è´¥: {short}")
                        elif not short:
                            logger.warning(f"é“¾æ¥ {i+1} è½¬æ¢è¿”å›ç©º: {original[:50]}...")
                except Exception as e:
                    logger.error(f"æ‰¹é‡çŸ­é“¾è½¬æ¢å¤±è´¥: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
                    short_urls = [None] * len(valid_links)
            else:
                short_urls = valid_links if not shortener_config.get("enabled", False) else [None] * len(valid_links)
            
            # ç»„åˆç»“æœ
            for idx, file_idx in enumerate(file_indices):
                file_info = files[file_idx]
                original_url = valid_links[idx]
                
                # è·å–çŸ­é“¾ï¼ˆå¦‚æœè½¬æ¢å¤±è´¥æˆ–æœªå¯ç”¨ï¼Œä½¿ç”¨åŸé“¾æ¥ï¼‰
                if shortener_config.get("enabled", False):
                    short_url = short_urls[idx] if not isinstance(short_urls[idx], Exception) and short_urls[idx] else original_url
                else:
                    short_url = original_url
                
                result.append({
                    "name": file_info["name"],
                    "url": short_url
                })
            
            logger.info(f"ç”ŸæˆOpenListé“¾æ¥æˆåŠŸï¼Œå…± {len(result)} ä¸ª")
            for link in result:
                logger.info(f"  - {link['name']}: {link['url']}")
            
            return result
            
        except Exception as e:
            logger.error(f"ç”ŸæˆOpenListé“¾æ¥å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return []
    
    def _decode_output(self, data: bytes) -> str:
        """å°è¯•å¤šç§ç¼–ç æ–¹å¼è§£ç è¾“å‡º
        
        ä¼˜å…ˆå°è¯•GBK/GB2312ï¼ˆWindowsä¸­æ–‡ç³»ç»Ÿå¸¸ç”¨ï¼‰ï¼Œç„¶åå°è¯•UTF-8
        """
        if not data:
            return ""
        
        # å°è¯•çš„ç¼–ç é¡ºåºï¼šGBK -> GB2312 -> UTF-8 -> latin1ï¼ˆæœ€åå…œåº•ï¼‰
        encodings = ["gbk", "gb2312", "utf-8", "latin1"]
        
        for encoding in encodings:
            try:
                decoded = data.decode(encoding, errors="strict")
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¹±ç ï¼ˆå¦‚æœè§£ç åå¤§éƒ¨åˆ†å­—ç¬¦éƒ½æ˜¯å¯æ‰“å°çš„ï¼Œè®¤ä¸ºæˆåŠŸï¼‰
                printable_ratio = sum(1 for c in decoded[:100] if c.isprintable() or c.isspace()) / min(len(decoded), 100)
                if printable_ratio > 0.7:  # 70%ä»¥ä¸Šæ˜¯å¯æ‰“å°å­—ç¬¦
                    return decoded
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨errors="ignore"ä½œä¸ºæœ€åæ‰‹æ®µ
        try:
            return data.decode("gbk", errors="ignore")
        except:
            return data.decode("utf-8", errors="ignore")

    async def _run_bbdown(self, cmd: list) -> tuple[int, str, str]:
        """è¿è¡Œ BBDown å‘½ä»¤"""
        try:
            # æ£€æŸ¥BBDownæ˜¯å¦å­˜åœ¨
            bbdown_path = cmd[0] if cmd else "BBDown"
            if bbdown_path == "BBDown" or not os.path.isabs(bbdown_path):
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„æˆ–å‘½ä»¤åï¼Œæ£€æŸ¥æ˜¯å¦åœ¨PATHä¸­
                import shutil
                if not shutil.which(bbdown_path):
                    error_msg = (
                        f"æ‰¾ä¸åˆ°BBDownå¯æ‰§è¡Œæ–‡ä»¶: {bbdown_path}\n"
                        f"è¯·ç¡®ä¿BBDownå·²å®‰è£…å¹¶åœ¨PATHä¸­ï¼Œæˆ–ä½¿ç”¨ /bili-set bbdown_path <å®Œæ•´è·¯å¾„> è®¾ç½®BBDownçš„å®Œæ•´è·¯å¾„\n"
                        f"ä¾‹å¦‚: /bili-set bbdown_path /usr/local/bin/BBDown"
                    )
                    logger.error(error_msg)
                    return -1, "", error_msg
            
            logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(shlex.quote(str(arg)) for arg in cmd)}")
            current_work_dir = os.getcwd()
            logger.debug(f"å½“å‰å·¥ä½œç›®å½•: {current_work_dir}")
            logger.debug(f"å¹³å°: {os.name}")  # 'nt' for Windows, 'posix' for Linux/Mac
            
            # åœ¨Linuxä¸Šï¼Œç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…è·¯å¾„è§£æé—®é¢˜
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=current_work_dir,
                env=os.environ.copy()  # æ˜¾å¼ä¼ é€’ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿PATHç­‰ç¯å¢ƒå˜é‡æ­£ç¡®
            )
            stdout, stderr = await process.communicate()
            return_code = process.returncode or -1
            
            # ä½¿ç”¨æ™ºèƒ½è§£ç 
            stdout_str = self._decode_output(stdout) if stdout else ""
            stderr_str = self._decode_output(stderr) if stderr else ""
            
            # è®°å½•è¾“å‡ºç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
            if stdout_str:
                logger.debug(f"BBDown stdoutå‰1000å­—ç¬¦: {stdout_str[:1000]}")
            if stderr_str:
                logger.debug(f"BBDown stderrå‰1000å­—ç¬¦: {stderr_str[:1000]}")
            logger.debug(f"BBDownè¿”å›ç : {return_code}")
            
            return return_code, stdout_str, stderr_str
        except FileNotFoundError as e:
            error_msg = (
                f"æ‰¾ä¸åˆ°BBDownå¯æ‰§è¡Œæ–‡ä»¶: {cmd[0] if cmd else 'BBDown'}\n"
                f"è¯·ç¡®ä¿BBDownå·²å®‰è£…å¹¶åœ¨PATHä¸­ï¼Œæˆ–ä½¿ç”¨ /bili-set bbdown_path <å®Œæ•´è·¯å¾„> è®¾ç½®BBDownçš„å®Œæ•´è·¯å¾„\n"
                f"ä¾‹å¦‚: /bili-set bbdown_path /usr/local/bin/BBDown"
            )
            logger.error(error_msg)
            return -1, "", error_msg
        except Exception as e:
            logger.error(f"æ‰§è¡Œ BBDown å‘½ä»¤å¤±è´¥: {e}")
            return -1, "", str(e)

    @filter.command("bili-help", alias={"bilibili-help", "bç«™å¸®åŠ©", "Bç«™å¸®åŠ©", "biliå¸®åŠ©"})
    async def show_help(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨å‘½ä»¤å’Œå¸®åŠ©ä¿¡æ¯"""
        help_msg = """ğŸ“š Bç«™è§†é¢‘ä¸‹è½½å™¨ - å‘½ä»¤å¸®åŠ©

ã€ä¸‹è½½ç›¸å…³ã€‘
/bili <è§†é¢‘URL>
  ä¸‹è½½Bç«™è§†é¢‘
  ç¤ºä¾‹: /bili https://www.bilibili.com/video/BV1qt4y1X7TW
  ç¤ºä¾‹: /bili https://b23.tv/uKe83H7
  ç¤ºä¾‹: /bili BV1qt4y1X7TW
  ç¤ºä¾‹: /bili ã€æ ‡é¢˜-å“”å“©å“”å“©ã€‘ https://b23.tv/xxx
  æ”¯æŒå®Œæ•´é“¾æ¥ã€çŸ­é“¾ï¼ˆb23.tvï¼‰ã€BVå·å’Œç§»åŠ¨ç«¯åˆ†äº«æ ¼å¼
  åˆ«å: /bilibili, /bç«™, /Bç«™

ã€é…ç½®ç›¸å…³ã€‘
/bili-set <é…ç½®é¡¹> <å€¼>
  è®¾ç½®æ’ä»¶é…ç½®
  é…ç½®é¡¹: bbdown_path, download_path, quality, danmaku, subtitle, single_pattern, multi_pattern
  ç¤ºä¾‹: /bili-set download_path ./videos
  ç¤ºä¾‹: /bili-set quality 1080P
  åˆ«å: /bilibili-set, /bç«™è®¾ç½®, /Bç«™è®¾ç½®

/bili-config
  æŸ¥çœ‹å½“å‰é…ç½®
  åˆ«å: /bilibili-config, /bç«™é…ç½®, /Bç«™é…ç½®

ã€Cookieç›¸å…³ã€‘
/bili-cookie <cookieå­—ç¬¦ä¸²>
  è®¾ç½®Bç«™Cookie
  æ”¯æŒå¤šç§æ ¼å¼ï¼šæµè§ˆå™¨æ ¼å¼ã€Netscapeæ ¼å¼ã€JSONæ ¼å¼ã€çº¯æ–‡æœ¬æ ¼å¼
  ç¤ºä¾‹: /bili-cookie SESSDATA=xxx; DedeUserID=xxx
  åˆ«å: /bilibili-cookie, /bç«™cookie, /Bç«™cookie

/bili-test-cookie [cookieå­—ç¬¦ä¸²]
  æµ‹è¯•Cookieæ˜¯å¦æœ‰æ•ˆ
  ä¸æä¾›å‚æ•°åˆ™æµ‹è¯•å½“å‰é…ç½®çš„Cookie
  åˆ«å: /bilibili-test-cookie, /bç«™æµ‹è¯•cookie, /Bç«™æµ‹è¯•cookie, /æµ‹è¯•cookie

ã€å‘½åæ ¼å¼ç›¸å…³ã€‘
/bili-naming
  æŸ¥çœ‹æ–‡ä»¶å‘½åæ ¼å¼å¯ç”¨å‚æ•°
  åˆ«å: /bilibili-naming, /bç«™å‘½å, /Bç«™å‘½å

ã€å¸®åŠ©ã€‘
/bili-help
  æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  åˆ«å: /bilibili-help, /bç«™å¸®åŠ©, /Bç«™å¸®åŠ©, /biliå¸®åŠ©

ğŸ’¡ æç¤ºï¼š
- ä½¿ç”¨ /bili-set æŸ¥çœ‹è¯¦ç»†çš„é…ç½®é¡¹è¯´æ˜
- ä½¿ç”¨ /bili-naming æŸ¥çœ‹å‘½åæ ¼å¼å‚æ•°åˆ—è¡¨
- ä¹Ÿå¯ä»¥åœ¨WebUIçš„æ’ä»¶é…ç½®é¡µé¢è¿›è¡Œè®¾ç½®
"""
        yield event.plain_result(help_msg)

    def _extract_url_from_text(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–Bç«™URL
        
        æ”¯æŒä»ä»¥ä¸‹æ ¼å¼æå–ï¼š
        - ã€æ ‡é¢˜-å“”å“©å“”å“©ã€‘ https://b23.tv/xxx
        - ç›´æ¥çš„URL
        - BVå·
        
        Args:
            text: å¯èƒ½åŒ…å«URLçš„æ–‡æœ¬
            
        Returns:
            æå–åˆ°çš„URLï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        if not text:
            return None
        
        # å…ˆå»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()
        
        # 1. å°è¯•åŒ¹é…å®Œæ•´çš„HTTP/HTTPSé“¾æ¥ï¼ˆåŒ…æ‹¬b23.tvçŸ­é“¾å’Œbilibili.comï¼‰
        # åŒ¹é…URLä¸­å¸¸è§çš„å­—ç¬¦ï¼šå­—æ¯ã€æ•°å­—ã€-ã€_ã€/ã€?ã€=ã€&ã€%ã€#ã€.ç­‰
        url_pattern = r'https?://(?:b23\.tv|(?:www\.)?bilibili\.com)/[a-zA-Z0-9_/?=&%#.-]+'
        url_match = re.search(url_pattern, text)
        if url_match:
            return url_match.group(0)
        
        # 2. å°è¯•åŒ¹é…BVå·
        bv_pattern = r'BV[a-zA-Z0-9]+'
        bv_match = re.search(bv_pattern, text)
        if bv_match:
            return bv_match.group(0)
        
        # 3. å¦‚æœéƒ½æ²¡åŒ¹é…åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯çº¯URLæˆ–BVå·ï¼ˆæ²¡æœ‰å…¶ä»–å­—ç¬¦ï¼‰
        # å¦‚æœåŒ…å«ä¸­æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦ï¼Œè¿”å›Noneè€Œä¸æ˜¯åŸæ–‡æœ¬
        if len(text) < 100 and not any('\u4e00' <= c <= '\u9fff' for c in text):
            # å¯èƒ½æ˜¯çº¯URLæˆ–BVå·ï¼Œè¿”å›åŸæ–‡æœ¬
            return text
        else:
            # åŒ…å«ä¸­æ–‡æˆ–å¤ªé•¿ï¼Œè‚¯å®šä¸æ˜¯çº¯URLï¼Œè¿”å›None
            return None
    
    async def _resolve_b23_shortlink(self, url: str) -> Optional[str]:
        """è§£æBç«™çŸ­é“¾ï¼ˆb23.tvï¼‰è·å–çœŸå®URL
        
        Args:
            url: Bç«™çŸ­é“¾URLï¼ˆå¦‚ https://b23.tv/xxxï¼‰
            
        Returns:
            çœŸå®URLï¼Œå¦‚æœè§£æå¤±è´¥è¿”å›None
        """
        if not url or "b23.tv" not in url:
            return None
        
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
        if not url.startswith("http://") and not url.startswith("https://"):
            url = "https://" + url
        
        try:
            async with aiohttp.ClientSession() as session:
                # å…ˆå°è¯•ä¸è·Ÿéšé‡å®šå‘ï¼Œè·å–Locationå¤´
                async with session.get(
                    url,
                    allow_redirects=False,
                    timeout=aiohttp.ClientTimeout(total=10, connect=5),
                    headers={
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                        "Referer": "https://www.bilibili.com/"
                    }
                ) as resp:
                    # æ£€æŸ¥é‡å®šå‘
                    if resp.status in (301, 302, 303, 307, 308):
                        location = resp.headers.get("Location")
                        if location:
                            # å¤„ç†ç›¸å¯¹è·¯å¾„
                            if location.startswith("/"):
                                location = urljoin(url, location)
                            logger.debug(f"Bç«™çŸ­é“¾è§£ææˆåŠŸï¼ˆé‡å®šå‘ï¼‰: {url} -> {location}")
                            return location
                
                # å¦‚æœæ²¡æœ‰é‡å®šå‘å¤´ï¼Œå°è¯•è·Ÿéšé‡å®šå‘è·å–æœ€ç»ˆURL
                async with session.get(
                    url,
                    allow_redirects=True,
                    timeout=aiohttp.ClientTimeout(total=10, connect=5),
                    headers={
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                        "Referer": "https://www.bilibili.com/"
                    }
                ) as resp:
                    if resp.status == 200:
                        final_url = str(resp.url)
                        # ç¡®ä¿æœ€ç»ˆURLæ˜¯Bç«™é“¾æ¥
                        if "bilibili.com" in final_url:
                            logger.debug(f"Bç«™çŸ­é“¾è§£ææˆåŠŸï¼ˆè·Ÿéšé‡å®šå‘ï¼‰: {url} -> {final_url}")
                            return final_url
                        else:
                            logger.warning(f"Bç«™çŸ­é“¾è§£æç»“æœä¸æ˜¯Bç«™é“¾æ¥: {url} -> {final_url}")
        except asyncio.TimeoutError:
            logger.warning(f"Bç«™çŸ­é“¾è§£æè¶…æ—¶: {url}")
        except aiohttp.ClientError as e:
            logger.warning(f"Bç«™çŸ­é“¾è§£æç½‘ç»œé”™è¯¯: {url}, é”™è¯¯: {e}")
        except Exception as e:
            logger.warning(f"Bç«™çŸ­é“¾è§£æå¤±è´¥: {url}, é”™è¯¯: {e}")
        
        return None
    
    def _extract_bv_from_url(self, url: str) -> Optional[str]:
        """ä»URLä¸­æå–BVå·"""
        # åŒ¹é…BVå·æ ¼å¼
        bv_match = re.search(r'BV[a-zA-Z0-9]+', url)
        if bv_match:
            return bv_match.group(0)
        # å¦‚æœURLä¸­æ²¡æœ‰BVå·ï¼ˆå¯èƒ½æ˜¯åŠ¨æ€é“¾æ¥å¦‚ t.bilibili.comï¼‰ï¼Œè¿”å›None
        # BBDownåº”è¯¥èƒ½å¤„ç†è¿™ç§é“¾æ¥ï¼Œæ‰€ä»¥è¿™é‡Œè¿”å›Noneæ˜¯å¯ä»¥çš„
        return None
    
    async def _get_video_info_from_api(self, url: str) -> tuple[bool, str, list]:
        """é€šè¿‡Bç«™APIè·å–è§†é¢‘ä¿¡æ¯
        
        Returns:
            tuple: (æ˜¯å¦æˆåŠŸ, è§†é¢‘æ ‡é¢˜, åˆ†Påˆ—è¡¨)
        """
        try:
            # æå–BVå·
            bv = self._extract_bv_from_url(url)
            if not bv:
                # å¦‚æœURLä¸­æ²¡æœ‰BVå·ï¼ˆå¯èƒ½æ˜¯åŠ¨æ€é“¾æ¥å¦‚ t.bilibili.comï¼‰ï¼Œ
                # ç›´æ¥è¿”å›å¤±è´¥ï¼Œè®©BBDownæ¥å¤„ç†ï¼ˆBBDownæ”¯æŒè¿™ç§é“¾æ¥ï¼‰
                logger.info(f"URLä¸­æœªåŒ…å«BVå·ï¼ˆå¯èƒ½æ˜¯åŠ¨æ€é“¾æ¥ï¼‰ï¼Œå°†ç›´æ¥ä½¿ç”¨BBDownä¸‹è½½: {url}")
                return False, "", []
            
            # Bç«™APIï¼šè·å–è§†é¢‘ä¿¡æ¯
            # ä½¿ç”¨webæ¥å£ï¼Œä¸éœ€è¦ç™»å½•
            api_url = f"https://api.bilibili.com/x/web-interface/view?bvid={bv}"
            
            # æ·»åŠ è¯·æ±‚å¤´æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œé¿å…è¢«åçˆ¬è™«æ‹¦æˆª
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Referer": "https://www.bilibili.com/",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            }
            
            async with aiohttp.ClientSession(headers=headers) as session:
                async with session.get(api_url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status != 200:
                        logger.error(f"APIè¯·æ±‚å¤±è´¥: {resp.status}")
                        return False, "", []
                    
                    data = await resp.json()
                    
                    if data.get("code") != 0:
                        logger.error(f"APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                        return False, "", []
                    
                    video_data = data.get("data", {})
                    if not video_data:
                        logger.error("APIè¿”å›æ•°æ®ä¸ºç©º")
                        return False, "", []
                    
                    # æå–è§†é¢‘æ ‡é¢˜
                    video_title = video_data.get("title", "")
                    
                    # æå–åˆ†Pä¿¡æ¯
                    pages = []
                    pages_data = video_data.get("pages", [])
                    
                    for page in pages_data:
                        pages.append({
                            "number": page.get("page", 0),
                            "cid": str(page.get("cid", "")),
                            "title": page.get("part", "")
                        })
                    
                    # æŒ‰åˆ†Påºå·æ’åº
                    pages.sort(key=lambda x: x["number"])
                    
                    logger.info(f"é€šè¿‡APIè·å–è§†é¢‘ä¿¡æ¯: æ ‡é¢˜={video_title}, åˆ†Pæ•°é‡={len(pages)}")
                    
                    return True, video_title, pages
                    
        except asyncio.TimeoutError:
            logger.error("è·å–è§†é¢‘ä¿¡æ¯è¶…æ—¶")
            return False, "", []
        except Exception as e:
            logger.error(f"é€šè¿‡APIè·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False, "", []
    
    async def _get_video_info(self, url: str) -> tuple[bool, str, list]:
        """è·å–è§†é¢‘ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨Bç«™APIï¼‰
        
        Returns:
            tuple: (æ˜¯å¦æˆåŠŸ, è§†é¢‘æ ‡é¢˜, åˆ†Påˆ—è¡¨)
        """
        # ä¼˜å…ˆä½¿ç”¨Bç«™APIè·å–ä¿¡æ¯ï¼ˆå¿«é€Ÿä¸”å¯é ï¼‰
        success, title, pages = await self._get_video_info_from_api(url)
        
        if success and title:
            return success, title, pages
        
        # å¦‚æœAPIå¤±è´¥ï¼Œè¿”å›å¤±è´¥ï¼ˆä¸å†å°è¯•BBDownï¼Œå› ä¸ºBBDownè·å–ä¿¡æ¯ä¹Ÿä¼šè¶…æ—¶ï¼‰
        logger.warning("APIè·å–è§†é¢‘ä¿¡æ¯å¤±è´¥")
        return False, "", []

    def _check_permission(self, event: AstrMessageEvent) -> tuple[bool, str | None]:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™ä½¿ç”¨å‘½ä»¤
        
        æƒé™è§„åˆ™ï¼š
        1. ç§èŠï¼šåªæœ‰ç®¡ç†å‘˜å¯ä»¥ä½¿ç”¨ï¼Œéç®¡ç†å‘˜é™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
        2. ç¾¤èŠï¼š
           - åªæœ‰åœ¨å¼€æ”¾ç¾¤ç»„åˆ—è¡¨ä¸­çš„ç¾¤ç»„æ‰èƒ½ä½¿ç”¨
           - å¦‚æœåœ¨å—é™ç¾¤ç»„é…ç½®ä¸­ï¼Œåªæœ‰é…ç½®çš„QQå·æ‰èƒ½ä½¿ç”¨
           - å¦‚æœä¸åœ¨ä»»ä½•åˆ—è¡¨ä¸­ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
           - å¦‚æœåœ¨å—é™ç¾¤ç»„é…ç½®ä¸­ä½†ç”¨æˆ·ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
        
        Returns:
            tuple: (æ˜¯å¦æœ‰æƒé™, é”™è¯¯æ¶ˆæ¯)
            - (True, ""): æœ‰æƒé™ï¼Œç»§ç»­æ‰§è¡Œ
            - (False, None): æ²¡æœ‰æƒé™ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
        """
        # è·å–ç¾¤IDå’Œç”¨æˆ·ID
        group_id = event.get_group_id()
        sender_id = event.get_sender_id()
        
        # å¦‚æœæ˜¯ç§èŠï¼Œåªæœ‰ç®¡ç†å‘˜å¯ä»¥ä½¿ç”¨
        if not group_id:
            if event.is_admin():
                return True, ""
            else:
                # ç§èŠéç®¡ç†å‘˜ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
                return False, None
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
        group_id_str = str(group_id).strip()
        sender_id_str = str(sender_id).strip()
        
        # è°ƒè¯•æ—¥å¿—
        logger.debug(f"æƒé™æ£€æŸ¥: ç¾¤ç»„ID={group_id_str}, ç”¨æˆ·ID={sender_id_str}, å¼€æ”¾ç¾¤ç»„åˆ—è¡¨={self.open_groups}, å—é™ç¾¤ç»„={self.restricted_groups}")
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å¼€æ”¾ç¾¤ç»„åˆ—è¡¨ä¸­
        if group_id_str in self.open_groups:
            # æ£€æŸ¥æ˜¯å¦åœ¨å—é™ç¾¤ç»„é…ç½®ä¸­ï¼ˆå—é™ç¾¤ç»„çš„ä¼˜å…ˆçº§æ›´é«˜ï¼‰
            if group_id_str in self.restricted_groups:
                allowed_users = self.restricted_groups[group_id_str]
                # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
                if isinstance(allowed_users, list):
                    if sender_id_str in allowed_users:
                        return True, ""
                    else:
                        # ç¾¤ç»„å·²é…ç½®ï¼Œä½†ç”¨æˆ·æ²¡æƒé™ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
                        return False, None
                else:
                    # å¦‚æœä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œè®°å½•é”™è¯¯ä½†å…è®¸ä½¿ç”¨ï¼ˆå®¹é”™å¤„ç†ï¼‰
                    logger.warning(f"å—é™ç¾¤ç»„ {group_id_str} çš„é…ç½®æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºåˆ—è¡¨")
                    return True, ""
            # å¦‚æœåœ¨å¼€æ”¾ç¾¤ç»„åˆ—è¡¨ä¸­ä¸”ä¸åœ¨å—é™ç¾¤ç»„é…ç½®ä¸­ï¼Œæ‰€æœ‰äººå¯ç”¨
            return True, ""
        
        # å¦‚æœä¸åœ¨å¼€æ”¾ç¾¤ç»„åˆ—è¡¨ä¸­ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
        return False, None
    
    @filter.command("bili", alias={"bilibili", "bç«™", "Bç«™"})
    async def download_video(self, event: AstrMessageEvent):
        """ä¸‹è½½Bç«™è§†é¢‘
        
        ç”¨æ³•: /bili <è§†é¢‘URL>
        ç¤ºä¾‹: /bili https://www.bilibili.com/video/BV1qt4y1X7TW
        
        å¦‚æœè§†é¢‘æœ‰å¤šä¸ªåˆ†Pï¼Œä¼šæç¤ºé€‰æ‹©ä¸‹è½½å…¨éƒ¨æˆ–æŒ‡å®šåˆ†P
        """
        # æ£€æŸ¥æƒé™
        has_permission, error_msg = self._check_permission(event)
        if not has_permission:
            # å¦‚æœerror_msgä¸ºNoneï¼Œè¡¨ç¤ºç¾¤ç»„æœªé…ç½®ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
            # å¦‚æœerror_msgä¸ä¸ºNoneï¼Œè¡¨ç¤ºæœ‰é…ç½®ä½†ç”¨æˆ·æ²¡æƒé™ï¼Œéœ€è¦å›å¤é”™è¯¯æ¶ˆæ¯
            if error_msg:
                yield event.plain_result(error_msg)
            return
        
        # ä»å®Œæ•´æ¶ˆæ¯ä¸­æå–URLï¼ˆå»é™¤å‘½ä»¤å‰ç¼€ï¼‰
        # æ³¨æ„ï¼ševent.message_str å·²ç»å»æ‰äº†æ–œæ ï¼Œæ‰€ä»¥æ˜¯ "bili xxx" è€Œä¸æ˜¯ "/bili xxx"
        message = event.message_str.strip()
        
        # ç§»é™¤å‘½ä»¤å‰ç¼€ï¼ˆbili, bilibili, bç«™, Bç«™ï¼‰
        url = ""
        for prefix in ["bili ", "bilibili ", "bç«™ ", "Bç«™ "]:
            if message.startswith(prefix):
                url = message[len(prefix):].strip()
                break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å¸¦ç©ºæ ¼çš„å‰ç¼€ï¼Œæ£€æŸ¥æ˜¯å¦åªæœ‰å‘½ä»¤æœ¬èº«
        if not url:
            for prefix in ["bili", "bilibili", "bç«™", "Bç«™"]:
                if message == prefix:
                    url = ""
                    break
        
        if not url:
            help_msg = """ğŸ“š Bç«™è§†é¢‘ä¸‹è½½å™¨

ç”¨æ³•: /bili <è§†é¢‘URL>

ç¤ºä¾‹:
/bili https://www.bilibili.com/video/BV1qt4y1X7TW
/bili https://b23.tv/uKe83H7
/bili BV1qt4y1X7TW
/bili ã€æ ‡é¢˜-å“”å“©å“”å“©ã€‘ https://b23.tv/xxx

ğŸ’¡ æç¤º:
- æ”¯æŒBç«™è§†é¢‘é“¾æ¥ã€çŸ­é“¾ï¼ˆb23.tvï¼‰å’ŒBVå·
- æ”¯æŒç›´æ¥ç²˜è´´ç§»åŠ¨ç«¯åˆ†äº«çš„å†…å®¹
- å¦‚æœè§†é¢‘æœ‰å¤šä¸ªåˆ†Pï¼Œä¼šæç¤ºé€‰æ‹©ä¸‹è½½
- ä½¿ç”¨ /bili-help æŸ¥çœ‹å®Œæ•´å¸®åŠ©"""
            yield event.plain_result(help_msg)
            return
        
        # ä»æ–‡æœ¬ä¸­æå–URLï¼ˆæ”¯æŒä»ç§»åŠ¨ç«¯åˆ†äº«çš„å†…å®¹ä¸­æå–ï¼‰
        extracted_url = self._extract_url_from_text(url)
        
        if extracted_url is None:
            # æå–å¤±è´¥ï¼Œè¿”å›é”™è¯¯
            yield event.plain_result("âŒ æ— æ³•ä»è¾“å…¥ä¸­æå–æœ‰æ•ˆçš„Bç«™è§†é¢‘é“¾æ¥\n\nè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š\n- https://www.bilibili.com/video/BV...\n- https://b23.tv/...\n- BVå·")
            return
        elif extracted_url != url:
            logger.info(f"ä»æ–‡æœ¬ä¸­æå–URL: {extracted_url}")
            url = extracted_url
        
        # å¦‚æœæ˜¯Bç«™çŸ­é“¾ï¼ˆb23.tvï¼‰ï¼Œå…ˆè§£æè·å–çœŸå®URL
        if "b23.tv" in url:
            yield event.plain_result("æ­£åœ¨è§£æçŸ­é“¾...")
            resolved_url = await self._resolve_b23_shortlink(url)
            if resolved_url:
                logger.info(f"çŸ­é“¾è§£ææˆåŠŸ: {url} -> {resolved_url}")
                url = resolved_url
            else:
                yield event.plain_result("âŒ æ— æ³•è§£æBç«™çŸ­é“¾ï¼Œè¯·ä½¿ç”¨å®Œæ•´é“¾æ¥æˆ–BVå·")
                return
        
        # éªŒè¯ URL
        if "bilibili.com" not in url and "BV" not in url and not url.startswith("BV"):
            yield event.plain_result("æ— æ•ˆçš„Bç«™è§†é¢‘URL")
            return
        
        yield event.plain_result("æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯...")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        success, video_title, pages = await self._get_video_info(url)
        
        logger.info(f"è·å–è§†é¢‘ä¿¡æ¯ç»“æœ: success={success}, title={video_title}, pages_count={len(pages)}")
        
        # å¦‚æœè·å–ä¿¡æ¯å¤±è´¥æˆ–æ²¡æœ‰æ ‡é¢˜ï¼Œç›´æ¥å°è¯•ä¸‹è½½
        if not success or not video_title:
            logger.warning("è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥æˆ–æ ‡é¢˜ä¸ºç©ºï¼Œç›´æ¥ä¸‹è½½")
            yield event.plain_result("å¼€å§‹ä¸‹è½½ï¼Œè¯·ç¨å€™...")
            current_config = self._get_current_config()
            classify_by_owner = current_config.get("classify_by_owner", True)
            cmd = self._build_bbdown_command(url)
            return_code, stdout, stderr = await self._run_bbdown(cmd)
        else:
            # å¦‚æœæœ‰å¤šä¸ªåˆ†Pï¼Œè®©ç”¨æˆ·é€‰æ‹©
            if len(pages) > 1:
                logger.info(f"æ£€æµ‹åˆ° {len(pages)} ä¸ªåˆ†Pï¼Œç­‰å¾…ç”¨æˆ·é€‰æ‹©")
                # æ˜¾ç¤ºåˆ†Påˆ—è¡¨
                pages_msg = f"ğŸ“¹ {video_title}\n\nå‘ç° {len(pages)} ä¸ªåˆ†Pï¼š\n"
                for page in pages:
                    pages_msg += f"  P{page['number']}: {page['title']}\n"
                pages_msg += "\nè¯·é€‰æ‹©ï¼š\n"
                pages_msg += "  â€¢ è¾“å…¥ 'all' æˆ– 'å…¨éƒ¨' - ä¸‹è½½å…¨éƒ¨åˆ†P\n"
                pages_msg += "  â€¢ è¾“å…¥æ•°å­—ï¼ˆå¦‚ 1, 2, 3ï¼‰ - ä¸‹è½½æŒ‡å®šåˆ†P\n"
                pages_msg += "  â€¢ è¾“å…¥èŒƒå›´ï¼ˆå¦‚ 1-3ï¼‰ - ä¸‹è½½æŒ‡å®šèŒƒå›´çš„åˆ†P\n"
                pages_msg += "  â€¢ è¾“å…¥å¤šä¸ªæ•°å­—ï¼ˆå¦‚ 1,3,5ï¼‰ - ä¸‹è½½å¤šä¸ªæŒ‡å®šåˆ†P\n"
                pages_msg += "\nğŸ’¡ 30ç§’å†…æœªé€‰æ‹©å°†è‡ªåŠ¨ä¸‹è½½å…¨éƒ¨"
                
                yield event.plain_result(pages_msg)
                
                # ç­‰å¾…ç”¨æˆ·é€‰æ‹©
                @session_waiter(timeout=30)  # type: ignore
                async def wait_page_selection(controller: SessionController, user_event: AstrMessageEvent):
                    # ä»äº‹ä»¶ä¸­æå–ç”¨æˆ·è¾“å…¥ï¼ˆä½¿ç”¨message_strå±æ€§ï¼‰
                    user_input = user_event.message_str.strip().lower()
                    
                    # è§£æç”¨æˆ·è¾“å…¥
                    selected_pages = None
                    
                    if user_input in ["all", "å…¨éƒ¨", "a", ""]:
                        selected_pages = "ALL"
                    elif "-" in user_input:
                        # èŒƒå›´é€‰æ‹©ï¼Œå¦‚ 1-3
                        try:
                            start, end = user_input.split("-", 1)
                            start = int(start.strip())
                            end = int(end.strip())
                            selected_pages = f"{start}-{end}"
                        except:
                            selected_pages = "ALL"
                    elif "," in user_input:
                        # å¤šä¸ªé€‰æ‹©ï¼Œå¦‚ 1,2,3
                        try:
                            page_nums = [int(p.strip()) for p in user_input.split(",")]
                            selected_pages = ",".join(map(str, page_nums))
                        except:
                            selected_pages = "ALL"
                    else:
                        # å•ä¸ªæ•°å­—
                        try:
                            page_num = int(user_input)
                            if 1 <= page_num <= len(pages):
                                selected_pages = str(page_num)
                            else:
                                selected_pages = "ALL"
                        except:
                            selected_pages = "ALL"
                    
                    # åœæ­¢ä¼šè¯å¹¶è¿”å›ç»“æœ
                    # ç›´æ¥è®¾ç½®futureçš„ç»“æœå€¼ï¼Œè€Œä¸æ˜¯è°ƒç”¨stop()ï¼ˆstop()ä¼šè®¾ç½®Noneï¼‰
                    if not controller.future.done():
                        controller.future.set_result(selected_pages)
                    return selected_pages
                
                try:
                    # session_waiterè£…é¥°çš„å‡½æ•°è°ƒç”¨æ—¶åªéœ€è¦ä¼ å…¥eventï¼Œè£…é¥°å™¨ä¼šè‡ªåŠ¨å¤„ç†
                    selected_pages = await wait_page_selection(event)
                    logger.info(f"ç”¨æˆ·é€‰æ‹©çš„åˆ†P: {selected_pages}")
                    if selected_pages is None:
                        selected_pages = "ALL"
                except Exception as e:
                    logger.warning(f"ç­‰å¾…ç”¨æˆ·é€‰æ‹©è¶…æ—¶æˆ–å‡ºé”™: {e}")
                    selected_pages = "ALL"
                
                # æ„å»ºä¸‹è½½å‘½ä»¤
                yield event.plain_result("å¼€å§‹ä¸‹è½½ï¼Œè¯·ç¨å€™...")
                
                current_config = self._get_current_config()
                classify_by_owner = current_config.get("classify_by_owner", True)
                cmd = self._build_bbdown_command(url, pages=selected_pages)
                return_code, stdout, stderr = await self._run_bbdown(cmd)
                
                # ä¿å­˜ç”¨æˆ·é€‰æ‹©çš„åˆ†Pä¿¡æ¯åˆ°å®ä¾‹å˜é‡ï¼Œç”¨äºåç»­è¾“å‡º
                self._last_selected_pages = selected_pages
            else:
                # å•ä¸ªè§†é¢‘æˆ–å•ä¸ªåˆ†Pï¼Œç›´æ¥ä¸‹è½½
                yield event.plain_result("å¼€å§‹ä¸‹è½½ï¼Œè¯·ç¨å€™...")
                
                current_config = self._get_current_config()
                classify_by_owner = current_config.get("classify_by_owner", True)
                cmd = self._build_bbdown_command(url)
                return_code, stdout, stderr = await self._run_bbdown(cmd)
        
        # åˆå¹¶è¾“å‡ºç”¨äºåˆ†æ
        output_combined = (stdout + "\n" + stderr).lower()
        output_original = stdout + "\n" + stderr
        
        # è®°å½•BBDownè¾“å‡ºç”¨äºè°ƒè¯•
        logger.debug(f"BBDownè¿”å›ç : {return_code}")
        logger.debug(f"BBDown stdoutå‰500å­—ç¬¦: {stdout[:500]}")
        if stderr:
            logger.debug(f"BBDown stderrå‰500å­—ç¬¦: {stderr[:500]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„é”™è¯¯ä¿¡æ¯ï¼ˆæ›´ä¸¥æ ¼çš„é”™è¯¯åˆ¤æ–­ï¼Œåªæ£€æŸ¥çœŸæ­£çš„é”™è¯¯ï¼‰
        error_keywords = [
            "unrecognized command", "unrecognized argument", 
            "command not found", "ä¸æ˜¯å†…éƒ¨æˆ–å¤–éƒ¨å‘½ä»¤",
            "error:", "failed to", "æ— æ³•", "ä¸èƒ½", "ä¸æ”¯æŒ"
        ]
        has_error_keyword = any(keyword.lower() in output_combined for keyword in error_keywords)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸæ ‡å¿—ï¼šè§†é¢‘ä¿¡æ¯ã€åˆ†Pä¿¡æ¯ã€UPä¸»ä¿¡æ¯ç­‰ï¼ˆæ›´å®½æ¾çš„åˆ¤æ–­ï¼‰
        # åªè¦è¾“å‡ºä¸­æœ‰è¿™äº›å…³é”®è¯ï¼Œå°±è®¤ä¸ºBBDownè‡³å°‘æˆåŠŸè§£æäº†è§†é¢‘ä¿¡æ¯
        success_indicators = [
            "aid:", "cid:",  # è§†é¢‘IDï¼ˆå…³é”®æ ‡å¿—ï¼‰
            "è§†é¢‘:", "è§†é¢‘æ ‡é¢˜:", "title:",  # è§†é¢‘æ ‡é¢˜
            "upä¸»", "upä¸»:", "owner", "space.bilibili.com",  # UPä¸»ä¿¡æ¯
            "p1:", "p2:", "p3:", "åˆ†p", "page",  # åˆ†Pä¿¡æ¯
            "è·å–aid", "è·å–è§†é¢‘", "è§†é¢‘ä¿¡æ¯",  # è·å–ä¿¡æ¯çš„è¿‡ç¨‹
            "ä¸‹è½½", "ä¿å­˜", "saved", "completed", "å®Œæˆ", "æˆåŠŸ",  # å®Œæˆæ ‡å¿—
            "version", "bbdown", "bilibili downloader"  # BBDownç‰ˆæœ¬ä¿¡æ¯ï¼ˆè¯´æ˜ç¨‹åºè¿è¡Œäº†ï¼‰
        ]
        has_success_indicator = any(indicator.lower() in output_combined for indicator in success_indicators)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¿å­˜çš„è·¯å¾„ä¿¡æ¯
        has_file_path = any(keyword in output_original for keyword in [".mp4", ".flv", ".m4s", "ä¿å­˜è‡³", "saved to", "æ–‡ä»¶"])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰BBDownç‰ˆæœ¬ä¿¡æ¯ï¼ˆè¯´æ˜ç¨‹åºè‡³å°‘å¯åŠ¨äº†ï¼‰
        has_bbdown_info = "bbdown version" in output_combined or "bilibili downloader" in output_combined
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…ä¸‹è½½å®Œæˆçš„æ ‡å¿—ï¼ˆå…³é”®ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼‰
        has_download_complete = any(keyword in output_original.lower() for keyword in [
            "ä¿å­˜è‡³", "saved to", "æ–‡ä»¶å·²ä¿å­˜", "ä¸‹è½½å®Œæˆ", "download completed",
            "æ–‡ä»¶:", "file:", ".mp4", ".flv", ".m4s", ".mkv"
        ])
        
        # åˆ¤æ–­æ˜¯å¦æˆåŠŸï¼š
        # 1. è¿”å›ç ä¸º0ï¼ˆæ ‡å‡†æˆåŠŸï¼‰- è¿™æ˜¯æœ€å¯é çš„åˆ¤æ–­ï¼Œå¦‚æœè¿”å›0é€šå¸¸è¡¨ç¤ºæˆåŠŸ
        # 2. æœ‰æˆåŠŸæ ‡å¿—ä¸”æ²¡æœ‰é”™è¯¯ï¼ˆæœ‰è§†é¢‘ä¿¡æ¯ä¸”æ²¡æœ‰æ˜æ˜¾é”™è¯¯ï¼‰
        # 3. æœ‰BBDownç‰ˆæœ¬ä¿¡æ¯ä¸”æœ‰è§†é¢‘ä¿¡æ¯ï¼Œä¸”æ²¡æœ‰é”™è¯¯ï¼ˆè¯´æ˜ç¨‹åºè¿è¡Œå¹¶è·å–äº†ä¿¡æ¯ï¼‰
        # 4. æœ‰æ–‡ä»¶è·¯å¾„ä¿¡æ¯ä¸”æ²¡æœ‰é”™è¯¯
        # 5. æœ‰ä¸‹è½½å®Œæˆæ ‡å¿—ï¼ˆå…³é”®ï¼šå¿…é¡»æœ‰å®é™…æ–‡ä»¶ä¿å­˜çš„è¿¹è±¡ï¼‰
        # æ³¨æ„ï¼šè¿”å›ç ä¸º0æ˜¯æœ€å¯é çš„åˆ¤æ–­ï¼Œå³ä½¿è¾“å‡ºä¸­æ²¡æœ‰ç‰¹å®šå…³é”®è¯ï¼Œä¹Ÿåº”è¯¥è®¤ä¸ºæˆåŠŸ
        is_success = (
            return_code == 0 or  # è¿”å›ç ä¸º0æ˜¯æœ€å¯é çš„åˆ¤æ–­
            (has_success_indicator and has_download_complete and not has_error_keyword) or
            (has_file_path and not has_error_keyword) or
            (has_bbdown_info and has_success_indicator and has_download_complete and not has_error_keyword)
        )
        
        # å¦‚æœæ²¡æœ‰ä¸‹è½½å®Œæˆçš„æ ‡å¿—ä½†è¿”å›ç ä¸º0ï¼Œè®°å½•ä¿¡æ¯ï¼ˆä¸æ˜¯è­¦å‘Šï¼Œå› ä¸ºè¿”å›ç 0é€šå¸¸è¡¨ç¤ºæˆåŠŸï¼‰
        if not has_download_complete and return_code == 0:
            logger.info("BBDownè¿”å›ç ä¸º0ï¼Œä½†è¾“å‡ºä¸­æœªæ£€æµ‹åˆ°æ–‡ä»¶ä¿å­˜å…³é”®è¯ï¼Œå°†æ£€æŸ¥ä¸‹è½½ç›®å½•ä¸­çš„å®é™…æ–‡ä»¶")
        
        if is_success:
            # æå–ä¸‹è½½ä¿¡æ¯
            result_msg = "âœ… ä¸‹è½½å®Œæˆï¼\n"
            result_msg += "â”€" * 30 + "\n"
            
            # æå–å…³é”®ä¿¡æ¯ï¼šè§†é¢‘æ ‡é¢˜å’Œåˆ†Pä¿¡æ¯
            video_title = ""
            page_info = []
            
            # åˆå¹¶stdoutå’Œstderræ¥æå–ä¿¡æ¯
            all_output = stdout + "\n" + stderr if stderr else stdout
            
            if all_output:
                lines = all_output.split("\n")
                for line in lines:
                    line_stripped = line.strip()
                    if not line_stripped:
                        continue
                    
                    # æå–è§†é¢‘æ ‡é¢˜ï¼ˆæ ¼å¼ï¼šè§†é¢‘æ ‡é¢˜: xxxï¼‰
                    if "è§†é¢‘æ ‡é¢˜:" in line_stripped:
                        title_part = line_stripped.split("è§†é¢‘æ ‡é¢˜:", 1)[-1].strip()
                        if title_part:
                            video_title = title_part
                            continue
                    
                    # æå–åˆ†Pä¿¡æ¯ï¼ˆæ ¼å¼ï¼šP1: [cid] [æ ‡é¢˜] [æ—¶é•¿]ï¼‰
                    # åŒ¹é…æ ¼å¼: P1: [34047132747] [Mr.Taxi] [01m08s]
                    page_match = re.search(r'P(\d+):\s*\[([^\]]+)\]\s*\[([^\]]+)\]', line_stripped)
                    if page_match:
                        page_num = page_match.group(1)
                        page_title = page_match.group(3)  # ç¬¬ä¸‰ä¸ªæ–¹æ‹¬å·ä¸­æ˜¯æ ‡é¢˜
                        page_info.append(f"P{page_num}: {page_title}")
            
            # æ„å»ºç»“æœæ¶ˆæ¯ï¼ˆåªæ˜¾ç¤ºæ ‡é¢˜å’Œå®é™…ä¸‹è½½çš„åˆ†Påˆ—è¡¨ï¼‰
            if video_title:
                result_msg += f"ğŸ“¹ {video_title}\n"
            
            if page_info:
                # å¦‚æœç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šåˆ†Pï¼Œåªæ˜¾ç¤ºé€‰ä¸­çš„åˆ†P
                # æ£€æŸ¥æ˜¯å¦æœ‰é€‰ä¸­çš„åˆ†Pä¿¡æ¯ï¼ˆä»å¤–éƒ¨ä½œç”¨åŸŸè·å–ï¼‰
                selected_pages_info = getattr(self, '_last_selected_pages', None)
                if selected_pages_info and selected_pages_info.upper() != "ALL":
                    # è§£æé€‰ä¸­çš„åˆ†P
                    selected_pages_list = []
                    if "," in selected_pages_info:
                        # å¤šä¸ªåˆ†Pï¼Œå¦‚ "1,2,3"
                        selected_pages_list = [int(p.strip()) for p in selected_pages_info.split(",")]
                    elif "-" in selected_pages_info:
                        # èŒƒå›´ï¼Œå¦‚ "1-3"
                        start, end = selected_pages_info.split("-", 1)
                        selected_pages_list = list(range(int(start.strip()), int(end.strip()) + 1))
                    else:
                        # å•ä¸ªåˆ†Pï¼Œå¦‚ "1"
                        try:
                            selected_pages_list = [int(selected_pages_info)]
                        except:
                            selected_pages_list = []
                    
                    # åªæ˜¾ç¤ºé€‰ä¸­çš„åˆ†P
                    filtered_pages = [p for p in page_info if any(f"P{num}:" in p for num in selected_pages_list)]
                    if filtered_pages:
                        # å¦‚æœåªæœ‰ä¸€ä¸ªåˆ†Pï¼Œç®€åŒ–æ˜¾ç¤º
                        if len(filtered_pages) == 1:
                            result_msg += f"ğŸ“Œ {filtered_pages[0]}\n"
                        else:
                            result_msg += "ğŸ“Œ å·²ä¸‹è½½åˆ†Pï¼š\n"
                            for page in filtered_pages:
                                result_msg += f"   â€¢ {page}\n"
                    else:
                        # å¦‚æœåªæœ‰ä¸€ä¸ªåˆ†Pï¼Œç®€åŒ–æ˜¾ç¤º
                        if len(page_info) == 1:
                            result_msg += f"ğŸ“Œ {page_info[0]}\n"
                        else:
                            result_msg += "ğŸ“Œ åˆ†Påˆ—è¡¨ï¼š\n"
                            for page in page_info:
                                result_msg += f"   â€¢ {page}\n"
                else:
                    # ä¸‹è½½å…¨éƒ¨ï¼Œæ˜¾ç¤ºæ‰€æœ‰åˆ†P
                    # å¦‚æœåªæœ‰ä¸€ä¸ªåˆ†Pï¼Œç®€åŒ–æ˜¾ç¤º
                    if len(page_info) == 1:
                        result_msg += f"ğŸ“Œ {page_info[0]}\n"
                    else:
                        result_msg += "ğŸ“Œ åˆ†Påˆ—è¡¨ï¼š\n"
                        for page in page_info:
                            result_msg += f"   â€¢ {page}\n"
            elif not video_title:
                # å¦‚æœæ²¡æœ‰æå–åˆ°ä¿¡æ¯ï¼Œæ˜¾ç¤ºé»˜è®¤æ¶ˆæ¯
                result_msg += "ä¸‹è½½å®Œæˆ"
            
            # ç”ŸæˆOpenListä¸‹è½½é“¾æ¥ï¼ˆç­‰å¾…æ–‡ä»¶å®Œå…¨å†™å…¥å¹¶ç¨³å®šï¼‰
            import asyncio
            
            # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆï¼šæ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¨³å®š
            logger.info("ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ...")
            await asyncio.sleep(2)  # å…ˆç­‰å¾…2ç§’
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¿˜åœ¨å†™å…¥ï¼ˆæ–‡ä»¶å¤§å°æ˜¯å¦ç¨³å®šï¼‰
            download_path = current_config.get("download_path", "./downloads")
            abs_download_path = os.path.abspath(download_path)
            
            if os.path.exists(abs_download_path):
                # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¨³å®šï¼ˆè¿ç»­3æ¬¡æ£€æŸ¥ï¼Œæ¯æ¬¡é—´éš”1ç§’ï¼Œå¤§å°ä¸å˜ï¼‰
                max_retries = 5
                stable_count = 0
                last_sizes = {}
                
                for retry in range(max_retries):
                    await asyncio.sleep(1)
                    # æ‰«æè§†é¢‘æ–‡ä»¶
                    video_extensions = ['.mp4', '.flv', '.m4s', '.mkv']
                    current_sizes = {}
                    
                    for root, dirs, files in os.walk(abs_download_path):
                        for file in files:
                            if any(file.lower().endswith(ext) for ext in video_extensions):
                                file_path = os.path.join(root, file)
                                try:
                                    file_size = os.path.getsize(file_path)
                                    # æ£€æŸ¥æ‰€æœ‰è§†é¢‘æ–‡ä»¶çš„å¤§å°
                                    if file_size > 0:  # åªæ£€æŸ¥å¤§å°å¤§äº0çš„æ–‡ä»¶
                                        current_sizes[file_path] = file_size
                                except:
                                    pass
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¨³å®š
                    if last_sizes:
                        all_stable = True
                        for file_path, current_size in current_sizes.items():
                            if file_path in last_sizes:
                                if current_size != last_sizes[file_path]:
                                    all_stable = False
                                    break
                        
                        if all_stable:
                            stable_count += 1
                            if stable_count >= 2:  # è¿ç»­2æ¬¡å¤§å°ä¸å˜ï¼Œè®¤ä¸ºæ–‡ä»¶å·²ç¨³å®š
                                logger.info(f"æ–‡ä»¶å¤§å°å·²ç¨³å®šï¼ˆæ£€æŸ¥äº†{retry+1}æ¬¡ï¼‰")
                                break
                    else:
                        stable_count += 1
                        if stable_count >= 2:
                            break
                    
                    last_sizes = current_sizes
                
                if stable_count < 2:
                    logger.warning("æ–‡ä»¶å¯èƒ½è¿˜åœ¨å†™å…¥ä¸­ï¼Œä½†å°†ç»§ç»­å°è¯•ç”Ÿæˆé“¾æ¥")
            
            selected_pages_info = getattr(self, '_last_selected_pages', None)
            # ä½¿ç”¨å¼‚æ­¥æ–¹å¼ç”Ÿæˆé“¾æ¥ï¼ˆå› ä¸ºéœ€è¦è°ƒç”¨OpenList APIï¼‰
            # é€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶
            alist_links = await self._generate_alist_links_async(
                current_config, video_title, page_info, selected_pages_info
            )
            if alist_links:
                result_msg += "â”€" * 30 + "\n"
                result_msg += "ğŸ“¥ ä¸‹è½½é“¾æ¥\n"
                result_msg += "â”€" * 30 + "\n"
                for i, link_info in enumerate(alist_links, 1):
                    # å¦‚æœåªæœ‰ä¸€ä¸ªé“¾æ¥ï¼Œç®€åŒ–æ˜¾ç¤º
                    if len(alist_links) == 1:
                        result_msg += f"ğŸ”— {link_info['url']}\n"
                    else:
                        result_msg += f"ã€{i}ã€‘{link_info['name']}\n"
                        result_msg += f"   ğŸ”— {link_info['url']}\n"
            else:
                logger.warning("æœªç”ŸæˆOpenListé“¾æ¥ï¼Œå¯èƒ½åŸå› ï¼šæ–‡ä»¶æœªæ‰¾åˆ°æˆ–æ–‡ä»¶åä¸åŒ¹é…")
            
            yield event.plain_result(result_msg.strip())
        else:
            # å¤±è´¥æƒ…å†µ
            error_msg = f"âŒ ä¸‹è½½å¤±è´¥"
            if return_code != 0:
                error_msg += f" (è¿”å›ç : {return_code})"
            error_msg += "\n\n"
            
            # åˆå¹¶è¾“å‡ºç”¨äºé”™è¯¯åˆ†æ
            all_output = (stdout + "\n" + stderr).lower() if stderr else stdout.lower()
            all_output_original = stdout + "\n" + stderr if stderr else stdout
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘ä¿¡æ¯ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æˆåŠŸè·å–åˆ°è§†é¢‘ï¼‰
            # æ›´ä¸¥æ ¼çš„åˆ¤æ–­ï¼šè‡³å°‘è¦æœ‰2ä¸ªå…³é”®ä¿¡æ¯æ‰è®¤ä¸ºè·å–åˆ°äº†è§†é¢‘
            video_info_keywords = ["aid:", "cid:", "è§†é¢‘æ ‡é¢˜:", "title:", "upä¸»", "owner", "bvid:"]
            video_info_count = sum(1 for keyword in video_info_keywords if keyword in all_output)
            has_video_info = video_info_count >= 2
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯BBDownæœªæ‰¾åˆ°çš„é”™è¯¯ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            if stderr and ("No such file or directory" in stderr or "æ‰¾ä¸åˆ°" in stderr or "command not found" in stderr.lower()):
                error_msg += "âš ï¸ BBDownæœªæ‰¾åˆ°æˆ–æ— æ³•æ‰§è¡Œ\n\n"
                error_msg += "è§£å†³æ–¹æ¡ˆï¼š\n"
                error_msg += "1. ç¡®ä¿BBDownå·²æ­£ç¡®å®‰è£…\n"
                error_msg += "2. å¦‚æœBBDownä¸åœ¨PATHä¸­ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®¾ç½®å®Œæ•´è·¯å¾„ï¼š\n"
                error_msg += "   /bili-set bbdown_path <BBDownçš„å®Œæ•´è·¯å¾„>\n"
                error_msg += "   ä¾‹å¦‚: /bili-set bbdown_path /usr/local/bin/BBDown\n"
                error_msg += "   æˆ–: /bili-set bbdown_path /home/user/BBDown/BBDown\n\n"
            # ä¼˜å…ˆæ£€æŸ¥ï¼šå¦‚æœè¿”å›ç é0ä¸”æ²¡æœ‰è§†é¢‘ä¿¡æ¯ï¼Œå¾ˆå¯èƒ½æ˜¯è§†é¢‘ä¸å­˜åœ¨ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
            elif return_code != 0 and not has_video_info:
                # ç›´æ¥åˆ¤æ–­ä¸ºè§†é¢‘ä¸å­˜åœ¨ï¼Œç®€æ´æ˜äº†
                error_msg += "âš ï¸ è§†é¢‘ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤\n\n"
                error_msg += "ğŸ’¡ å»ºè®®ï¼š\n"
                error_msg += "- åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€é“¾æ¥ç¡®è®¤è§†é¢‘æ˜¯å¦å¯è®¿é—®\n"
                error_msg += "- å¦‚æœè§†é¢‘ç¡®å®å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦ç™»å½•ï¼Œè¯·ä½¿ç”¨ /bili-test-cookie æ£€æŸ¥CookieçŠ¶æ€\n\n"
            # æ£€æŸ¥è¾“å‡ºä¸­æ˜¯å¦æœ‰æ˜ç¡®çš„"è§†é¢‘ä¸å­˜åœ¨"ç›¸å…³é”™è¯¯
            elif any(keyword in all_output_original for keyword in [
                "è§†é¢‘ä¸å­˜åœ¨", "è§†é¢‘å·²åˆ é™¤", "è§†é¢‘å·²ä¸‹æ¶", "è§†é¢‘ä¸å¯ç”¨", "è§†é¢‘æ— æ•ˆ",
                "not found", "ä¸å­˜åœ¨", "æ— æ³•è®¿é—®", "è®¿é—®å¤±è´¥", "è·å–å¤±è´¥",
                "è§†é¢‘ä¿¡æ¯è·å–å¤±è´¥", "è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥", "è§£æå¤±è´¥", "è§£æé”™è¯¯",
                "invalid video", "invalid url", "æ— æ•ˆçš„è§†é¢‘", "æ— æ•ˆçš„é“¾æ¥"
            ]):
                error_msg += "âš ï¸ è§†é¢‘ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤\n\n"
                error_msg += "ğŸ’¡ å»ºè®®ï¼š\n"
                error_msg += "- åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€é“¾æ¥ç¡®è®¤è§†é¢‘æ˜¯å¦å¯è®¿é—®\n"
                error_msg += "- å¦‚æœè§†é¢‘ç¡®å®å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦ç™»å½•ï¼Œè¯·ä½¿ç”¨ /bili-test-cookie æ£€æŸ¥CookieçŠ¶æ€\n\n"
            # æ£€æŸ¥æ˜¯å¦æ˜¯Cookieç›¸å…³çš„é”™è¯¯ï¼ˆè¾ƒä½ä¼˜å…ˆçº§ï¼‰
            # æ³¨æ„ï¼šåªæœ‰å½“æœ‰å®Œæ•´è§†é¢‘ä¿¡æ¯ï¼ˆè‡³å°‘2ä¸ªå…³é”®å­—æ®µï¼‰ä½†Cookieæœ‰æ˜ç¡®é—®é¢˜æ—¶ï¼Œæ‰åˆ¤æ–­ä¸ºCookieé”™è¯¯
            # "æ£€æµ‹è´¦å·ç™»å½•"åªæ˜¯BBDownçš„å¸¸è§„è¾“å‡ºï¼Œä¸ä»£è¡¨Cookieæœ‰é—®é¢˜
            # åªæœ‰æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚"ç™»å½•å¤±è´¥""cookieå¤±æ•ˆ"ï¼‰æ‰åˆ¤æ–­ä¸ºCookieé—®é¢˜
            elif has_video_info and any(keyword in all_output for keyword in [
                "cookieå¤±æ•ˆ", "cookieæ— æ•ˆ", "ç™»å½•å¤±è´¥", "ç™»å½•é”™è¯¯", "æœªç™»å½•",
                "éœ€è¦ç™»å½•", "è¯·å…ˆç™»å½•", "è®¤è¯å¤±è´¥", "unauthorized", "æœªæˆæƒ",
                "è´¦å·å¼‚å¸¸", "è´¦æˆ·å¼‚å¸¸", "ç™»å½•çŠ¶æ€å¤±æ•ˆ"
            ]):
                error_msg += "âš ï¸ Cookieå¤±æ•ˆæˆ–éœ€è¦ç™»å½•\n\n"
                error_msg += "ğŸ’¡ å»ºè®®ï¼š\n"
                error_msg += "- ä½¿ç”¨ /bili-test-cookie æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆ\n"
                error_msg += "- å¦‚æœCookieå¤±æ•ˆï¼Œè¯·ä½¿ç”¨ /bili-cookie é‡æ–°è®¾ç½®\n\n"
            # å…¶ä»–æœªæ˜ç¡®åˆ†ç±»çš„é”™è¯¯ï¼ˆå…œåº•å¤„ç†ï¼‰
            else:
                error_msg += "âš ï¸ ä¸‹è½½å¤±è´¥\n\n"
                error_msg += "ğŸ’¡ å»ºè®®ï¼š\n"
                error_msg += "- åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€é“¾æ¥ç¡®è®¤è§†é¢‘æ˜¯å¦å¯è®¿é—®\n"
                error_msg += "- ä½¿ç”¨ /bili-test-cookie æ£€æŸ¥CookieçŠ¶æ€\n"
                error_msg += "- å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·ç¨åé‡è¯•\n\n"
            
            # ä¸å†æ˜¾ç¤ºBBDownçš„åŸå§‹è¾“å‡ºä¿¡æ¯ï¼Œåªæ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º
            yield event.plain_result(error_msg.strip())

    async def _test_cookie(self, cookie: str) -> tuple[bool, str, dict]:
        """æµ‹è¯•Cookieæ˜¯å¦æœ‰æ•ˆ
        
        Returns:
            tuple: (æ˜¯å¦æœ‰æ•ˆ, æ¶ˆæ¯, ç”¨æˆ·ä¿¡æ¯å­—å…¸)
        """
        try:
            parsed_cookie = self._parse_cookie(cookie)
            if not parsed_cookie:
                return False, "Cookieæ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æ", {}
            
            # è°ƒç”¨Bç«™APIè·å–ç”¨æˆ·ä¿¡æ¯
            url = "https://api.bilibili.com/x/space/myinfo"
            headers = {
                "Cookie": parsed_cookie,
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Referer": "https://www.bilibili.com/",
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status != 200:
                        return False, f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status}", {}
                    
                    data = await resp.json()
                    code = data.get("code", -1)
                    
                    if code != 0:
                        message = data.get("message", "æœªçŸ¥é”™è¯¯")
                        return False, f"Cookieæ— æ•ˆ: {message}", {}
                    
                    user_data = data.get("data", {})
                    if not user_data:
                        return False, "Cookieæ— æ•ˆ: æœªè·å–åˆ°ç”¨æˆ·ä¿¡æ¯", {}
                    
                    return True, "Cookieæœ‰æ•ˆ", user_data
                    
        except asyncio.TimeoutError:
            return False, "è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥", {}
        except Exception as e:
            logger.error(f"æµ‹è¯•Cookieå¤±è´¥: {e}")
            return False, f"æµ‹è¯•å¤±è´¥: {str(e)}", {}

    @filter.command("bili-test-cookie", alias={"bilibili-test-cookie", "bç«™æµ‹è¯•cookie", "Bç«™æµ‹è¯•cookie", "æµ‹è¯•cookie"})
    async def test_cookie(self, event: AstrMessageEvent, cookie: str = ""):
        """æµ‹è¯•Bç«™Cookieæ˜¯å¦æœ‰æ•ˆ
        
        ç”¨æ³•: /bili-test-cookie [cookieå­—ç¬¦ä¸²]
        å¦‚æœä¸æä¾›cookieï¼Œåˆ™æµ‹è¯•å½“å‰é…ç½®çš„cookie
        """
        # è·å–è¦æµ‹è¯•çš„cookie
        cookie_to_test = cookie
        if not cookie_to_test:
            # ä»é…ç½®è·å–
            current_config = self._get_current_config()
            cookie_to_test = current_config.get("cookie", "")
            if not cookie_to_test:
                yield event.plain_result(
                    "è¯·æä¾›è¦æµ‹è¯•çš„Cookie\n"
                    "ç”¨æ³•: /bili-test-cookie <cookieå­—ç¬¦ä¸²>\n"
                    "æˆ–è€…å…ˆè®¾ç½®Cookieåä½¿ç”¨: /bili-test-cookie"
                )
                return
        
        yield event.plain_result("æ­£åœ¨æµ‹è¯•Cookieï¼Œè¯·ç¨å€™...")
        
        # æµ‹è¯•cookie
        is_valid, message, user_data = await self._test_cookie(cookie_to_test)
        
        if is_valid:
            # æå–ç”¨æˆ·ä¿¡æ¯
            user_name = user_data.get("name", "æœªçŸ¥")
            user_id = user_data.get("mid", "æœªçŸ¥")
            level = user_data.get("level_info", {}).get("current_level", "æœªçŸ¥")
            vip_status = user_data.get("vip", {}).get("status", 0)
            vip_type = user_data.get("vip", {}).get("type", 0)
            
            vip_text = "æœªå¼€é€š" if vip_status == 0 else ("å¤§ä¼šå‘˜" if vip_type == 2 else "å¹´åº¦å¤§ä¼šå‘˜")
            
            result_msg = f"""âœ… Cookieæµ‹è¯•æˆåŠŸï¼

ğŸ‘¤ ç”¨æˆ·ä¿¡æ¯ï¼š
ç”¨æˆ·å: {user_name}
ç”¨æˆ·ID: {user_id}
ç­‰çº§: LV{level}
ä¼šå‘˜çŠ¶æ€: {vip_text}

ğŸ’¡ æç¤ºï¼šæ­¤Cookieå¯ä»¥æ­£å¸¸ä½¿ç”¨
"""
            yield event.plain_result(result_msg)
        else:
            result_msg = f"""âŒ Cookieæµ‹è¯•å¤±è´¥

{message}

ğŸ’¡ æç¤ºï¼š
1. è¯·æ£€æŸ¥Cookieæ˜¯å¦å·²è¿‡æœŸ
2. è¯·ç¡®è®¤Cookieæ ¼å¼æ˜¯å¦æ­£ç¡®
3. å¯ä»¥é‡æ–°ä»æµè§ˆå™¨å¤åˆ¶Cookie
"""
            yield event.plain_result(result_msg)

    @filter.command("bili-cookie", alias={"bilibili-cookie", "bç«™cookie", "Bç«™cookie"})
    async def set_cookie(self, event: AstrMessageEvent, cookie: str = ""):
        """è®¾ç½®Bç«™Cookie
        
        ç”¨æ³•: /bili-cookie <cookieå­—ç¬¦ä¸²>
        æ”¯æŒå¤šç§æ ¼å¼ï¼š
        1. æµè§ˆå™¨æ ¼å¼: name1=value1; name2=value2
        2. Netscapeæ ¼å¼: ä»æµè§ˆå™¨å¯¼å‡ºçš„cookieæ–‡ä»¶
        3. JSONæ ¼å¼: {"name": "value"}
        4. çº¯æ–‡æœ¬æ ¼å¼: name=value (å¤šè¡Œ)
        """
        # æ£€æŸ¥æƒé™ï¼ˆè®¾ç½®Cookieéœ€è¦æƒé™ï¼‰
        has_permission, error_msg = self._check_permission(event)
        if not has_permission:
            # å¦‚æœerror_msgä¸ºNoneï¼Œè¡¨ç¤ºç¾¤ç»„æœªé…ç½®ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
            # å¦‚æœerror_msgä¸ä¸ºNoneï¼Œè¡¨ç¤ºæœ‰é…ç½®ä½†ç”¨æˆ·æ²¡æƒé™ï¼Œéœ€è¦å›å¤é”™è¯¯æ¶ˆæ¯
            if error_msg:
                yield event.plain_result(error_msg)
            return
        
        if not cookie:
            yield event.plain_result(
                "è¯·æä¾›Cookie\n"
                "ç”¨æ³•: /bili-cookie <cookieå­—ç¬¦ä¸²>\n"
                "æ”¯æŒå¤šç§æ ¼å¼ï¼Œç¨‹åºä¼šè‡ªåŠ¨è¯†åˆ«"
            )
            return
        
        try:
            # è§£æ cookie
            parsed_cookie = self._parse_cookie(cookie)
            
            if not parsed_cookie:
                yield event.plain_result("Cookie è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ ¼å¼")
                return
            
            # ä¿å­˜åˆ°é…ç½®
            self.config["cookie"] = parsed_cookie
            
            # å¦‚æœconfigæ˜¯AstrBotConfigç±»å‹ï¼Œä½¿ç”¨å…¶save_configæ–¹æ³•
            plugin_metadata = self.context.get_registered_star("bilidownloader")
            if plugin_metadata and plugin_metadata.config:
                plugin_metadata.config["cookie"] = parsed_cookie
                plugin_metadata.config.save_config()
                # åŒæ­¥æ›´æ–°åˆ°self.config
                self.config = dict(plugin_metadata.config)
            else:
                # å¦åˆ™æ‰‹åŠ¨ä¿å­˜ï¼ˆå…¼å®¹æ—§æ–¹å¼ï¼‰
                self._save_config()
            
            # æ˜¾ç¤ºè®¾ç½®ç»“æœï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
            display_cookie = parsed_cookie
            if len(display_cookie) > 100:
                display_cookie = display_cookie[:50] + "..." + display_cookie[-50:]
            # éšè—æ•æ„Ÿå€¼
            display_cookie = re.sub(r'(SESSDATA|DedeUserID|bili_jct)=[^;]+', r'\1=***', display_cookie)
            
            yield event.plain_result(f"Cookie è®¾ç½®æˆåŠŸï¼\nå·²è§£ææ ¼å¼: {display_cookie}")
        except Exception as e:
            logger.error(f"è®¾ç½® Cookie å¤±è´¥: {e}")
            yield event.plain_result(f"è®¾ç½® Cookie å¤±è´¥: {str(e)}")

    def _save_config_to_file(self, config_key: str, value):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        plugin_metadata = self.context.get_registered_star("bilidownloader")
        if plugin_metadata and plugin_metadata.config:
            # å¤„ç†åµŒå¥—é…ç½®
            if "." in config_key:
                keys = config_key.split(".")
                config = plugin_metadata.config
                for key in keys[:-1]:
                    if key not in config:
                        config[key] = {}
                    config = config[key]
                config[keys[-1]] = value
            else:
                plugin_metadata.config[config_key] = value
            
            plugin_metadata.config.save_config()
            # åŒæ­¥æ›´æ–°åˆ°self.config
            self.config = dict(plugin_metadata.config)
            
            # å¦‚æœæ˜¯è·¯å¾„ç›¸å…³é…ç½®ï¼Œæ›´æ–°å®ä¾‹å˜é‡
            if config_key == "download_path":
                self.download_path = value
                os.makedirs(self.download_path, exist_ok=True)
            elif config_key == "bbdown_path":
                self.bbdown_path = value
        else:
            # å…¼å®¹æ—§æ–¹å¼
            if "." in config_key:
                keys = config_key.split(".")
                config = self.config
                for key in keys[:-1]:
                    if key not in config:
                        config[key] = {}
                    config = config[key]
                config[keys[-1]] = value
            else:
                self.config[config_key] = value
            self._save_config()

    @filter.command("bili-set", alias={"bilibili-set", "bç«™è®¾ç½®", "Bç«™è®¾ç½®"})
    async def set_config(self, event: AstrMessageEvent, key: str = "", value: str = ""):
        """è®¾ç½®æ’ä»¶é…ç½®
        
        ç”¨æ³•: /bili-set <é…ç½®é¡¹> <å€¼>
        
        å¯ç”¨é…ç½®é¡¹ï¼š
        - bbdown_path: BBDownå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
        - download_path: ä¸‹è½½ä¿å­˜è·¯å¾„
        - classify_by_owner: æŒ‰UPä¸»åç§°åˆ†ç±»æ–‡ä»¶å¤¹ï¼ˆtrue/false æˆ– æ˜¯/å¦ï¼‰
        - quality: é»˜è®¤æ¸…æ™°åº¦ï¼ˆ8K/4K/1080P60/1080P/720P60/720P/480P/360Pï¼Œç•™ç©ºè¡¨ç¤ºè‡ªåŠ¨ï¼‰
        - danmaku: æ˜¯å¦ä¸‹è½½å¼¹å¹•ï¼ˆtrue/false æˆ– æ˜¯/å¦ï¼‰
        - subtitle: æ˜¯å¦ä¸‹è½½å­—å¹•ï¼ˆtrue/false æˆ– æ˜¯/å¦ï¼‰
        - single_pattern: å•ä¸ªè§†é¢‘å‘½åæ ¼å¼
        - multi_pattern: åˆ†Pè§†é¢‘å‘½åæ ¼å¼
        
        ç¤ºä¾‹ï¼š
        /bili-set download_path ./videos
        /bili-set quality 1080P
        /bili-set danmaku true
        /bili-set single_pattern <è§†é¢‘æ ‡é¢˜>[<æ¸…æ™°åº¦>]
        """
        # æ£€æŸ¥æƒé™ï¼ˆè®¾ç½®é…ç½®éœ€è¦æƒé™ï¼‰
        has_permission, error_msg = self._check_permission(event)
        if not has_permission:
            # å¦‚æœerror_msgä¸ºNoneï¼Œè¡¨ç¤ºç¾¤ç»„æœªé…ç½®ï¼Œé™é»˜å¿½ç•¥ï¼ˆä¸å›å¤ï¼‰
            # å¦‚æœerror_msgä¸ä¸ºNoneï¼Œè¡¨ç¤ºæœ‰é…ç½®ä½†ç”¨æˆ·æ²¡æƒé™ï¼Œéœ€è¦å›å¤é”™è¯¯æ¶ˆæ¯
            if error_msg:
                yield event.plain_result(error_msg)
            return
        
        if not key:
            help_msg = """ğŸ“ è®¾ç½®æ’ä»¶é…ç½®

ç”¨æ³•: /bili-set <é…ç½®é¡¹> <å€¼>

å¯ç”¨é…ç½®é¡¹ï¼š
â€¢ bbdown_path - BBDownå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
â€¢ download_path - ä¸‹è½½ä¿å­˜è·¯å¾„
â€¢ classify_by_owner - æŒ‰UPä¸»åç§°åˆ†ç±»æ–‡ä»¶å¤¹ï¼ˆtrue/false æˆ– æ˜¯/å¦ï¼‰
â€¢ quality - é»˜è®¤æ¸…æ™°åº¦ï¼ˆ8K/4K/1080P60/1080P/720P60/720P/480P/360Pï¼Œç•™ç©ºè¡¨ç¤ºè‡ªåŠ¨ï¼‰
â€¢ danmaku - æ˜¯å¦ä¸‹è½½å¼¹å¹•ï¼ˆtrue/false æˆ– æ˜¯/å¦ï¼‰
â€¢ subtitle - æ˜¯å¦ä¸‹è½½å­—å¹•ï¼ˆtrue/false æˆ– æ˜¯/å¦ï¼‰
â€¢ single_pattern - å•ä¸ªè§†é¢‘å‘½åæ ¼å¼
â€¢ multi_pattern - åˆ†Pè§†é¢‘å‘½åæ ¼å¼

ç¤ºä¾‹ï¼š
/bili-set download_path ./videos
/bili-set quality 1080P
/bili-set danmaku true
/bili-set single_pattern <è§†é¢‘æ ‡é¢˜>[<æ¸…æ™°åº¦>]

ğŸ’¡ æç¤ºï¼šä¹Ÿå¯ä»¥ä½¿ç”¨WebUIé…ç½®é¡µé¢è¿›è¡Œè®¾ç½®
"""
            yield event.plain_result(help_msg)
            return
        
        if not value:
            yield event.plain_result(f"è¯·æä¾›é…ç½®å€¼\nç”¨æ³•: /bili-set {key} <å€¼>")
            return
        
        try:
            # å¤„ç†ä¸åŒçš„é…ç½®é¡¹
            if key == "bbdown_path":
                self._save_config_to_file("bbdown_path", value)
                yield event.plain_result(f"âœ… BBDownè·¯å¾„å·²è®¾ç½®ä¸º: {value}")
                
            elif key == "download_path":
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(value, exist_ok=True)
                self._save_config_to_file("download_path", value)
                yield event.plain_result(f"âœ… ä¸‹è½½è·¯å¾„å·²è®¾ç½®ä¸º: {value}")
                
            elif key == "classify_by_owner":
                # è§£æå¸ƒå°”å€¼
                bool_value = value.lower() in ["true", "1", "yes", "æ˜¯", "å¼€å¯", "on"]
                self._save_config_to_file("classify_by_owner", bool_value)
                yield event.plain_result(f"âœ… æŒ‰UPä¸»åˆ†ç±»å·²è®¾ç½®ä¸º: {'æ˜¯' if bool_value else 'å¦'}")
                
            elif key == "quality":
                # éªŒè¯æ¸…æ™°åº¦å€¼
                valid_qualities = ["8K", "4K", "1080P60", "1080P", "720P60", "720P", "480P", "360P", ""]
                if value not in valid_qualities:
                    yield event.plain_result(
                        f"âŒ æ— æ•ˆçš„æ¸…æ™°åº¦å€¼: {value}\n"
                        f"å¯é€‰å€¼: {', '.join([q for q in valid_qualities if q])} æˆ–ç•™ç©ºï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰"
                    )
                    return
                self._save_config_to_file("default_options.quality", value)
                quality_text = value if value else "è‡ªåŠ¨é€‰æ‹©"
                yield event.plain_result(f"âœ… é»˜è®¤æ¸…æ™°åº¦å·²è®¾ç½®ä¸º: {quality_text}")
                
            elif key == "danmaku":
                # è§£æå¸ƒå°”å€¼
                bool_value = value.lower() in ["true", "1", "yes", "æ˜¯", "å¼€å¯", "on"]
                self._save_config_to_file("default_options.download_danmaku", bool_value)
                yield event.plain_result(f"âœ… ä¸‹è½½å¼¹å¹•å·²è®¾ç½®ä¸º: {'æ˜¯' if bool_value else 'å¦'}")
                
            elif key == "subtitle":
                # è§£æå¸ƒå°”å€¼
                bool_value = value.lower() in ["true", "1", "yes", "æ˜¯", "å¼€å¯", "on"]
                self._save_config_to_file("default_options.download_subtitle", bool_value)
                yield event.plain_result(f"âœ… ä¸‹è½½å­—å¹•å·²è®¾ç½®ä¸º: {'æ˜¯' if bool_value else 'å¦'}")
                
            elif key == "single_pattern":
                self._save_config_to_file("naming.single_video_pattern", value)
                yield event.plain_result(f"âœ… å•ä¸ªè§†é¢‘å‘½åæ ¼å¼å·²è®¾ç½®ä¸º:\n{value}")
                
            elif key == "multi_pattern":
                self._save_config_to_file("naming.multi_video_pattern", value)
                yield event.plain_result(f"âœ… åˆ†Pè§†é¢‘å‘½åæ ¼å¼å·²è®¾ç½®ä¸º:\n{value}")
                
            else:
                yield event.plain_result(
                    f"âŒ æœªçŸ¥çš„é…ç½®é¡¹: {key}\n"
                    "ä½¿ç”¨ /bili-set æŸ¥çœ‹å¯ç”¨é…ç½®é¡¹"
                )
                
        except Exception as e:
            logger.error(f"è®¾ç½®é…ç½®å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ è®¾ç½®å¤±è´¥: {str(e)}")

    @filter.command("bili-config", alias={"bilibili-config", "bç«™é…ç½®", "Bç«™é…ç½®"})
    async def show_config(self, event: AstrMessageEvent):
        """æŸ¥çœ‹å½“å‰é…ç½®"""
        # é‡æ–°ä»metadataè·å–æœ€æ–°é…ç½®
        plugin_metadata = self.context.get_registered_star("bilidownloader")
        if plugin_metadata and plugin_metadata.config:
            current_config = dict(plugin_metadata.config)
        else:
            current_config = self.config
        
        naming_config = current_config.get("naming", {})
        single_pattern = naming_config.get("single_video_pattern", "<videoTitle>[<dfn>]")
        multi_pattern = naming_config.get("multi_video_pattern", "<videoTitle>/[P<pageNumberWithZero>]<pageTitle>[<dfn>]")
        
        classify_by_owner = current_config.get('classify_by_owner', True)
        config_info = f"""å½“å‰é…ç½®ï¼š
ä¸‹è½½è·¯å¾„: {current_config.get('download_path', './downloads')}
BBDownè·¯å¾„: {current_config.get('bbdown_path', 'BBDown')}
Cookie: {'å·²è®¾ç½®' if current_config.get('cookie') else 'æœªè®¾ç½®'}
æŒ‰UPä¸»åˆ†ç±»: {'æ˜¯' if classify_by_owner else 'å¦'}
é»˜è®¤æ¸…æ™°åº¦: {current_config.get('default_options', {}).get('quality', 'æœªè®¾ç½®') or 'è‡ªåŠ¨é€‰æ‹©'}
ä¸‹è½½å¼¹å¹•: {'æ˜¯' if current_config.get('default_options', {}).get('download_danmaku', False) else 'å¦'}
ä¸‹è½½å­—å¹•: {'æ˜¯' if current_config.get('default_options', {}).get('download_subtitle', True) else 'å¦'}

æ–‡ä»¶å‘½åæ ¼å¼ï¼š
å•ä¸ªè§†é¢‘: {single_pattern}
åˆ†Pè§†é¢‘: {multi_pattern}

ğŸ’¡ æç¤ºï¼šå¯åœ¨WebUIçš„æ’ä»¶é…ç½®é¡µé¢ä¿®æ”¹è¿™äº›è®¾ç½®
"""
        yield event.plain_result(config_info)

    @filter.command("bili-naming", alias={"bilibili-naming", "bç«™å‘½å", "Bç«™å‘½å"})
    async def show_naming_params(self, event: AstrMessageEvent):
        """æŸ¥çœ‹æ–‡ä»¶å‘½åå¯ç”¨å‚æ•°"""
        params_info = """ğŸ“ æ–‡ä»¶å‘½åæ ¼å¼å¯ç”¨å‚æ•°ï¼ˆç›´æ¥ä½¿ç”¨ä¸­æ–‡å‚æ•°åå³å¯ï¼‰

ã€å•ä¸ªè§†é¢‘å¯ç”¨å‚æ•°ã€‘
<è§†é¢‘æ ‡é¢˜>        - è§†é¢‘çš„æ ‡é¢˜
<BVå·>           - è§†é¢‘çš„BVå·ï¼ˆå¦‚ï¼šBV1234567890ï¼‰
<AID>            - è§†é¢‘çš„AID
<CID>            - è§†é¢‘çš„CID
<æ¸…æ™°åº¦>          - è§†é¢‘æ¸…æ™°åº¦ï¼ˆå¦‚ï¼š1080Pã€720Pã€4Kç­‰ï¼‰
<åˆ†è¾¨ç‡>          - è§†é¢‘åˆ†è¾¨ç‡ï¼ˆå¦‚ï¼š1920x1080ï¼‰
<å¸§ç‡>            - è§†é¢‘å¸§ç‡ï¼ˆå¦‚ï¼š30ã€60ï¼‰
<è§†é¢‘ç¼–ç >        - è§†é¢‘ç¼–ç æ ¼å¼ï¼ˆå¦‚ï¼šavcã€hevcï¼‰
<è§†é¢‘ç ç‡>        - è§†é¢‘ç ç‡
<éŸ³é¢‘ç¼–ç >        - éŸ³é¢‘ç¼–ç æ ¼å¼
<éŸ³é¢‘ç ç‡>        - éŸ³é¢‘ç ç‡
<UPä¸»åç§°>        - ä¸Šä¼ è§†é¢‘çš„UPä¸»åå­—
<UPä¸»MID>         - UPä¸»çš„MIDå·
<å‘å¸ƒæ—¶é—´>        - è§†é¢‘å‘å¸ƒæ—¶é—´ï¼ˆæ ¼å¼ï¼š2024-01-01_12-00-00ï¼‰
<APIç±»å‹>         - APIç±»å‹ï¼ˆTV/APP/INTL/WEBï¼‰

ã€åˆ†Pè§†é¢‘é¢å¤–å‚æ•°ã€‘
<åˆ†Påºå·>         - åˆ†Påºå·ï¼ˆå¦‚ï¼š1ã€2ã€10ï¼‰
<åˆ†Påºå·è¡¥é›¶>     - åˆ†Påºå·å¸¦å‰å¯¼é›¶ï¼ˆå¦‚ï¼š01ã€02ã€10ï¼‰
<åˆ†Pæ ‡é¢˜>         - æ¯ä¸ªåˆ†Pçš„æ ‡é¢˜

ğŸ“Œ ä½¿ç”¨ç¤ºä¾‹ï¼š

ã€å•ä¸ªè§†é¢‘ã€‘
æ ¼å¼ï¼š<è§†é¢‘æ ‡é¢˜>[<æ¸…æ™°åº¦>]
ç»“æœï¼šæˆ‘çš„è§†é¢‘æ ‡é¢˜[1080P].mp4

æ ¼å¼ï¼š<UPä¸»åç§°>-<è§†é¢‘æ ‡é¢˜>-<æ¸…æ™°åº¦>
ç»“æœï¼šå¼ ä¸‰-æˆ‘çš„è§†é¢‘æ ‡é¢˜-1080P.mp4

æ ¼å¼ï¼š<è§†é¢‘æ ‡é¢˜>-<BVå·>[<æ¸…æ™°åº¦>]
ç»“æœï¼šæˆ‘çš„è§†é¢‘æ ‡é¢˜-BV1234567890[1080P].mp4

ã€åˆ†Pè§†é¢‘ã€‘
æ ¼å¼ï¼š<è§†é¢‘æ ‡é¢˜>/[P<åˆ†Påºå·è¡¥é›¶>]<åˆ†Pæ ‡é¢˜>[<æ¸…æ™°åº¦>]
ç»“æœï¼š
  æˆ‘çš„è§†é¢‘æ ‡é¢˜/[P01]ç¬¬ä¸€é›†[1080P].mp4
  æˆ‘çš„è§†é¢‘æ ‡é¢˜/[P02]ç¬¬äºŒé›†[1080P].mp4

æ ¼å¼ï¼š<UPä¸»åç§°>-<è§†é¢‘æ ‡é¢˜>/P<åˆ†Påºå·>-<åˆ†Pæ ‡é¢˜>
ç»“æœï¼š
  å¼ ä¸‰-æˆ‘çš„è§†é¢‘æ ‡é¢˜/P1-ç¬¬ä¸€é›†.mp4
  å¼ ä¸‰-æˆ‘çš„è§†é¢‘æ ‡é¢˜/P2-ç¬¬äºŒé›†.mp4

ğŸ’¡ æç¤ºï¼š
- ç›´æ¥ä½¿ç”¨ä¸­æ–‡å‚æ•°åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è½¬æ¢
- å¯åœ¨WebUIçš„æ’ä»¶é…ç½®é¡µé¢è®¾ç½®å‘½åæ ¼å¼
- å‚æ•°åéœ€è¦ç”¨å°–æ‹¬å· <> åŒ…è£¹
"""
        yield event.plain_result(params_info)

    def _save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶ï¼ˆå…¼å®¹æ–¹æ³•ï¼Œå½“configä¸æ˜¯AstrBotConfigæ—¶ä½¿ç”¨ï¼‰"""
        try:
            config_path = os.path.join("data", "config", "bilidownloader_config.json")
            os.makedirs(os.path.dirname(config_path), exist_ok=True)
            with open(config_path, "w", encoding="utf-8") as f:
                json.dump(self.config, f, indent=4, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
